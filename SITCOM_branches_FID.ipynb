{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cheng-HanHuang/Phase_Retrieval_SITCOM/blob/main/SITCOM_branches_FID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "yh4r9xxrB4gy"
      },
      "id": "yh4r9xxrB4gy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup: clone private repo + attach pretrained models\n",
        "\n",
        "from getpass import getpass\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "REPO_URL = \"github.com/Cheng-HanHuang/Phase_Retrieval_SITCOM.git\"\n",
        "REPO_DIR = \"/content/Phase_Retrieval_SITCOM\"\n",
        "\n",
        "# 1. Clone the private repo if needed\n",
        "if not os.path.exists(REPO_DIR):\n",
        "    print(\"Cloning private repo. You need a GitHub Personal Access Token with repo access.\")\n",
        "    token = getpass(\"Enter your GitHub token (input hidden): \").strip()\n",
        "    # Note: don't hard-code token in the notebook; always type it when prompted\n",
        "    !git clone https://{token}@{REPO_URL} $REPO_DIR\n",
        "else:\n",
        "    print(f\"Repo already exists at {REPO_DIR}\")\n",
        "\n",
        "# 2. Change to repo directory\n",
        "%cd $REPO_DIR\n",
        "print(\"Working directory:\", os.getcwd())\n",
        "\n",
        "# 3. Ensure gdown is available\n",
        "!pip install -q gdown\n",
        "\n",
        "# 4. Ensure models/ exists inside the repo\n",
        "MODEL_DIR = os.path.join(REPO_DIR, \"models\")\n",
        "FILE_ID = \"1TIWltvBRfuO7C5B9NQCNJM7O4LDSxTOD\"\n",
        "\n",
        "# Case 1: you already downloaded models earlier to /content/models\n",
        "if os.path.exists(\"/content/models\") and not os.path.exists(MODEL_DIR):\n",
        "    print(\"Found existing /content/models, moving it into the repo...\")\n",
        "    shutil.move(\"/content/models\", MODEL_DIR)\n",
        "\n",
        "# Case 2: no models yet anywhere → download into repo\n",
        "if not os.path.exists(MODEL_DIR):\n",
        "    print(\"No models found; downloading from Google Drive with gdown...\")\n",
        "    TAR_NAME = \"models_ffhq_sitcom.tar.gz\"\n",
        "    !gdown \"https://drive.google.com/uc?id=$FILE_ID\" -O $TAR_NAME\n",
        "    print(\"Download complete, extracting...\")\n",
        "    !tar -xzf $TAR_NAME\n",
        "    !rm $TAR_NAME\n",
        "\n",
        "print(\"Final models directory tree:\")\n",
        "!ls -R models\n",
        "print(\"Setup complete ✅\")\n"
      ],
      "metadata": {
        "id": "C2wgj366vT_H",
        "outputId": "fedec767-a599-4523-d5d6-9bc0ac315760",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "C2wgj366vT_H",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Repo already exists at /content/Phase_Retrieval_SITCOM\n",
            "/content/Phase_Retrieval_SITCOM\n",
            "Working directory: /content/Phase_Retrieval_SITCOM\n",
            "Final models directory tree:\n",
            "models:\n",
            "256x256_diffusion_uncond.pt  ffhq_10m.pt  imagenet256.pt\n",
            "Setup complete ✅\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4f456362-d33a-44ca-9edf-692d6785d735",
      "metadata": {
        "id": "4f456362-d33a-44ca-9edf-692d6785d735"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "import os\n",
        "import argparse\n",
        "import yaml\n",
        "# import pandas as pd\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import inception_v3\n",
        "from util.img_utils import Blurkernel#, ifft2_m,fft2_m\n",
        "from guided_diffusion.fastmri_utils import fft2c_new,ifft2c_new\n",
        "from guided_diffusion.condition_methods import get_conditioning_method\n",
        "from guided_diffusion.measurements import get_noise, get_operator\n",
        "from guided_diffusion.unet import create_model\n",
        "from guided_diffusion.gaussian_diffusion_correct import create_sampler\n",
        "from data.dataloader import get_dataset, get_dataloader\n",
        "from util.img_utils import clear_color, mask_generator\n",
        "from util.logger import get_logger\n",
        "from common_utils import *\n",
        "from ddim_sampler import *\n",
        "import shutil\n",
        "# import lpips\n",
        "from scheduling_ddpm import DDPMScheduler\n",
        "from functools import partial\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e2032631",
      "metadata": {
        "id": "e2032631"
      },
      "outputs": [],
      "source": [
        "np.random.seed(41)\n",
        "torch.manual_seed(41)\n",
        "torch.cuda.manual_seed_all(41)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "35c36b2e",
      "metadata": {
        "id": "35c36b2e"
      },
      "outputs": [],
      "source": [
        "def load_yaml(file_path: str) -> dict:\n",
        "    with open(file_path) as f:\n",
        "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
        "    return config\n",
        "\n",
        "model_config     = \"configs/model_config.yaml\"\n",
        "diffusion_config = \"configs/diffusion_config.yaml\"\n",
        "task_config      = \"configs/phase_retrieval_config.yaml\"\n",
        "\n",
        "# Check device (on colab)\n",
        "print(\"torch.cuda.is_available():\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Device count:\", torch.cuda.device_count())\n",
        "    print(\"Current device:\", torch.cuda.current_device())\n",
        "    print(\"Device name:\", torch.cuda.get_device_name(0))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Load configurations\n",
        "model_config = load_yaml(model_config)\n",
        "diffusion_config = load_yaml(diffusion_config)\n",
        "task_config = load_yaml(task_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "52ae3256",
      "metadata": {
        "id": "52ae3256"
      },
      "outputs": [],
      "source": [
        "model = create_model(**model_config)\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Prepare Operator and noise\n",
        "measure_config = task_config['measurement']\n",
        "operator = get_operator(device=device, **measure_config['operator'])\n",
        "noiser = get_noise(**measure_config['noise'])\n",
        "#logger.info(f\"Operation: {measure_config['operator']['name']} / Noise: {measure_config['noise']['name']}\")\n",
        "\n",
        "# Prepare conditioning method\n",
        "cond_config = task_config['conditioning']\n",
        "cond_method = get_conditioning_method(cond_config['method'], operator, noiser, **cond_config['params'])\n",
        "measurement_cond_fn = cond_method.conditioning\n",
        "#logger.info(f\"Conditioning method : {task_config['conditioning']['method']}\")\n",
        "\n",
        "# Prepare dataloader\n",
        "data_config = task_config['data']\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "dataset = get_dataset(**data_config, transforms=transform)\n",
        "loader = get_dataloader(dataset, batch_size=1, num_workers=0, train=False)\n",
        "\n",
        "# Exception) In case of inpainting, we need to generate a mask\n",
        "if measure_config['operator']['name'] == 'inpainting':\n",
        "    mask_gen = mask_generator(\n",
        "       **measure_config['mask_opt']\n",
        "    )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "185766bd",
      "metadata": {
        "id": "185766bd"
      },
      "outputs": [],
      "source": [
        "\n",
        "scheduler = DDIMScheduler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "09517520",
      "metadata": {
        "id": "09517520"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.L1Loss().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c602327e",
      "metadata": {
        "id": "c602327e"
      },
      "outputs": [],
      "source": [
        "losses = []\n",
        "psnrs = []\n",
        "out_visual = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "edbf2b61",
      "metadata": {
        "id": "edbf2b61"
      },
      "outputs": [],
      "source": [
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1.0  # Assuming the image is normalized to [0, 1]\n",
        "    psnr = 20 * np.log10(max_pixel / (mse**0.5))\n",
        "    return psnr.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "927ee0a0",
      "metadata": {
        "id": "927ee0a0"
      },
      "outputs": [],
      "source": [
        "def compute_mce(reconstructed_image, measured_magnitude, target_shape=None):\n",
        "    \"\"\"Compute L2 error between Fourier magnitude of reconstruction and measured magnitude.\"\"\"\n",
        "    x_hat = reconstructed_image\n",
        "\n",
        "    # Pad to match measurement shape (e.g., 384x384)\n",
        "    if target_shape is not None:\n",
        "        _, _, H, W = x_hat.shape\n",
        "        target_H, target_W = target_shape[-2], target_shape[-1]\n",
        "        pad_h = (target_H - H) // 2\n",
        "        pad_w = (target_W - W) // 2\n",
        "        x_hat = F.pad(x_hat, (pad_w, pad_w, pad_h, pad_h))\n",
        "\n",
        "    # Ensure complex\n",
        "    if not torch.is_complex(x_hat):\n",
        "        x_hat = x_hat.type(torch.complex64)\n",
        "\n",
        "    # Compute FFT and error\n",
        "    fft_x_hat = torch.view_as_complex(fft2c_new(torch.view_as_real(x_hat)))\n",
        "    magnitude_error = (fft_x_hat.abs() - measured_magnitude).pow(2).mean()\n",
        "    return magnitude_error.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "02f9a3cb-f2f1-462d-bc7c-7f375ad0ef32",
      "metadata": {
        "id": "02f9a3cb-f2f1-462d-bc7c-7f375ad0ef32"
      },
      "outputs": [],
      "source": [
        "def optimize_input(input,  sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod, t,\n",
        "                   num_steps=20, learning_rate=0.01):\n",
        "    \"\"\"\n",
        "    Inner measurement-consistency optimization at diffusion step t.\n",
        "    input: current x_t (no grad required)\n",
        "    Returns: (x_t_new, x0_pred, noise_pred)\n",
        "    \"\"\"\n",
        "    # treat the incoming x_t as a constant anchor for the proximity term\n",
        "    input_anchor = input.detach()\n",
        "\n",
        "    # create a fresh leaf variable to optimize\n",
        "    x_t = input_anchor.clone().requires_grad_(True)\n",
        "    opt = torch.optim.Adam([x_t], lr=learning_rate)\n",
        "\n",
        "    tt = torch.full((1,), int(t), device=x_t.device, dtype=torch.long)\n",
        "\n",
        "    x0 = None  # keep last x0 for returning\n",
        "    for _ in range(num_steps):\n",
        "        opt.zero_grad()\n",
        "\n",
        "        # predict noise and x0\n",
        "        noise_pred = model(x_t, tt)[:, :3]\n",
        "        x0 = (x_t - sqrt_one_minus_alpha_cumprod * noise_pred) / sqrt_alpha_cumprod\n",
        "        x0 = x0.clamp(-1, 1)\n",
        "\n",
        "        # your current forward: manual FFT magnitude pipeline\n",
        "        pad = int((2 / 8.0) * 256)\n",
        "        x01 = (x0 * 0.5 + 0.5).clamp(0, 1)\n",
        "        xpad = F.pad(x01, (pad, pad, pad, pad))\n",
        "        if not torch.is_complex(xpad):\n",
        "            xpad = xpad.type(torch.complex64)\n",
        "        fft2_m = torch.view_as_complex(fft2c_new(torch.view_as_real(xpad)))\n",
        "        out = fft2_m.abs()\n",
        "\n",
        "        # data term + proximity (anchor is detached, so no outer graph reuse)\n",
        "        loss_mc  = torch.norm(out - y_n)**2\n",
        "        loss_reg = 0.1 * torch.norm(x_t - input_anchor)**2\n",
        "        loss = loss_mc + loss_reg\n",
        "\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        # optional visualization – detach to avoid holding graphs\n",
        "        back_y = ifft2c_new(torch.view_as_real(fft2_m.type(torch.complex64)))\n",
        "        back_y = torch.view_as_complex(back_y).detach()\n",
        "        # out_visual.append(back_y)\n",
        "\n",
        "    # recover (optional) noise from final pair\n",
        "    noise = (x_t - sqrt_alpha_cumprod * x0) / sqrt_one_minus_alpha_cumprod\n",
        "    return x_t.detach(), x0.detach(), noise.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a91a6d5d",
      "metadata": {
        "id": "a91a6d5d"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Branching & Scoring Utils\n",
        "# =========================\n",
        "\n",
        "# -- Optional: LPIPS (already imported in your file)\n",
        "# Make a lazy/global holder so we don't re-create the network each call\n",
        "_LPIPS_MODEL = None\n",
        "_INCEPTION = None\n",
        "\n",
        "def get_lpips_model(device):\n",
        "    global _LPIPS_MODEL\n",
        "    if _LPIPS_MODEL is None:\n",
        "        _LPIPS_MODEL = lpips.LPIPS(net='vgg').to(device).eval()\n",
        "    return _LPIPS_MODEL\n",
        "\n",
        "'''def get_inception(device):\n",
        "    \"\"\"\n",
        "    Lightweight inception for FID features (pool3 ~ 2048-d). Using torchvision's inception_v3.\n",
        "    We take features from the last pooling layer before classification.\n",
        "    NOTE: FID is meaningful only against a dataset's (mu, Sigma). For per-image demo, we provide\n",
        "    a 'proxy FID' versus a provided real reference (gt) or precomputed stats.\n",
        "    \"\"\"\n",
        "    global _INCEPTION\n",
        "    if _INCEPTION is None:\n",
        "        inc = inception_v3(pretrained=True, transform_input=False, aux_logits=False)\n",
        "        inc.fc = torch.nn.Identity()  # drop classifier head; output is 2048 features\n",
        "        _INCEPTION = inc.to(device).eval()\n",
        "    return _INCEPTION'''\n",
        "\n",
        "from torchvision.models import inception_v3\n",
        "try:\n",
        "    # Newer torchvision\n",
        "    from torchvision.models.inception import Inception_V3_Weights\n",
        "    _INCEPTION_WEIGHTS = Inception_V3_Weights.IMAGENET1K_V1\n",
        "except Exception:\n",
        "    # Fallback if enum not available\n",
        "    _INCEPTION_WEIGHTS = None\n",
        "\n",
        "_INCEPTION = None\n",
        "\n",
        "def get_inception(device):\n",
        "    \"\"\"\n",
        "    Load InceptionV3 for FID features (pool3 ~ 2048-d).\n",
        "    Uses torchvision's weights API; we *don't* override aux_logits/transform_input,\n",
        "    to avoid the ValueError you saw.\n",
        "    \"\"\"\n",
        "    global _INCEPTION\n",
        "    if _INCEPTION is None:\n",
        "        if _INCEPTION_WEIGHTS is not None:\n",
        "            # Let weights decide aux_logits & transform_input\n",
        "            inc = inception_v3(weights=_INCEPTION_WEIGHTS)\n",
        "        else:\n",
        "            # Very old torchvision: fall back to pretrained=True\n",
        "            inc = inception_v3(pretrained=True)\n",
        "\n",
        "        # Drop classifier head → we only want features\n",
        "        inc.fc = nn.Identity()\n",
        "\n",
        "        # Aux logits are only used in training mode; we're in eval() anyway.\n",
        "        # No need to delete, but we *could* do:\n",
        "        # if hasattr(inc, \"AuxLogits\"):\n",
        "        #     inc.AuxLogits = nn.Identity()\n",
        "\n",
        "        inc = inc.to(device).eval()\n",
        "        _INCEPTION = inc\n",
        "    return _INCEPTION\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def _inception_acts(img_bchw_01, device):\n",
        "    \"\"\"\n",
        "    img_bchw_01: float tensor in [0,1], Bx3xHxW (H,W >= 75 preferred)\n",
        "    returns: Bx2048 features\n",
        "    \"\"\"\n",
        "    inc = get_inception(device)\n",
        "    # InceptionV3 expects roughly [-1,1]\n",
        "    x = img_bchw_01 # * 2 - 1\n",
        "    # Resize to 299 if needed\n",
        "    if x.shape[-1] != 299 or x.shape[-2] != 299:\n",
        "        x = F.interpolate(x, size=(299, 299), mode='bilinear', align_corners=False)\n",
        "    feats = inc(x)\n",
        "\n",
        "    # if isinstance(feats, (tuple, list)):\n",
        "        # feats = feats[0]\n",
        "\n",
        "    return feats\n",
        "\n",
        "def compute_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Classic FID formula between two Gaussians N(mu1, Sigma1) and N(mu2, Sigma2).\n",
        "    For per-image 'proxy FID', you can set (mu1,sigma1) to the candidate's single-vector stats\n",
        "    and (mu2,sigma2) to a real reference (e.g., dataset stats). This is only a demo proxy.\n",
        "    \"\"\"\n",
        "    diff = mu1 - mu2\n",
        "    # product might be not PSD numerically; add eps\n",
        "    covmean = torch.linalg.sqrtm((sigma1 @ sigma2).cpu().double()).real.to(sigma1.device)\n",
        "    if not torch.isfinite(covmean).all():\n",
        "        # numerical fallback\n",
        "        offset = torch.eye(sigma1.shape[0], device=sigma1.device) * eps\n",
        "        covmean = torch.linalg.sqrtm(((sigma1 + offset) @ (sigma2 + offset)).cpu().double()).real.to(sigma1.device) # This line is wrong\n",
        "    tr_covmean = torch.trace(covmean)\n",
        "    fid = diff @ diff + torch.trace(sigma1 + sigma2 - 2*covmean)\n",
        "    return (fid.float()).item()\n",
        "\n",
        "def _matrix_sqrt_torch(A, eps=1e-10):\n",
        "    \"\"\"\n",
        "    Compute symmetric matrix square root of A using eigen-decomposition.\n",
        "    Assumes A is (approximately) symmetric PSD.\n",
        "    \"\"\"\n",
        "    # Symmetrize for safety\n",
        "    A = 0.5 * (A + A.t())\n",
        "\n",
        "    # Eigen-decomposition\n",
        "    eigvals, eigvecs = torch.linalg.eigh(A)   # [d], [d,d]\n",
        "\n",
        "    # Clamp eigenvalues to avoid negative small values from numerical noise\n",
        "    eigvals_clamped = torch.clamp(eigvals, min=eps)\n",
        "    sqrt_eigvals = torch.sqrt(eigvals_clamped)\n",
        "\n",
        "    # Reconstruct sqrt(A) = Q diag(sqrt(λ)) Q^T\n",
        "    return (eigvecs * sqrt_eigvals.unsqueeze(0)) @ eigvecs.t()\n",
        "\n",
        "\n",
        "def compute_frechet_distance(mu1, sigma1, mu2, sigma2, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Classic FID formula between two Gaussians N(mu1, Sigma1) and N(mu2, Sigma2),\n",
        "    implemented fully in PyTorch using eigen-decomposition for the matrix square root.\n",
        "    \"\"\"\n",
        "    # Ensure floating tensors\n",
        "    mu1 = mu1.float()\n",
        "    mu2 = mu2.float()\n",
        "    sigma1 = sigma1.float()\n",
        "    sigma2 = sigma2.float()\n",
        "\n",
        "    diff = mu1 - mu2  # [d]\n",
        "\n",
        "    # Product of covariances\n",
        "    cov_prod = sigma1 @ sigma2\n",
        "\n",
        "    # Try matrix sqrt of the symmetric product\n",
        "    try:\n",
        "        covmean = _matrix_sqrt_torch(cov_prod)\n",
        "    except Exception as e:\n",
        "        # Numerical fallback: regularize both covariances\n",
        "        dim = sigma1.shape[0]\n",
        "        offset = torch.eye(dim, device=sigma1.device) * eps\n",
        "        cov_prod_reg = (sigma1 + offset) @ (sigma2 + offset)\n",
        "        covmean = _matrix_sqrt_torch(cov_prod_reg)\n",
        "\n",
        "    # If still bad, do a last-resort regularization\n",
        "    if not torch.isfinite(covmean).all():\n",
        "        dim = sigma1.shape[0]\n",
        "        offset = torch.eye(dim, device=sigma1.device) * (10 * eps)\n",
        "        cov_prod_reg = (sigma1 + offset) @ (sigma2 + offset)\n",
        "        covmean = _matrix_sqrt_torch(cov_prod_reg)\n",
        "\n",
        "    tr_covmean = torch.trace(covmean)\n",
        "\n",
        "    fid = diff @ diff + torch.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "    return fid.item()\n",
        "\n",
        "\n",
        "def compute_proxy_fid(\n",
        "    x0_img_01,                  # 1x3xHxW, [0,1]\n",
        "    device,\n",
        "    real_stats=None,            # dict with 'mu':(2048,), 'sigma':(2048,2048) tensors on device\n",
        "    real_ref_img_01=None        # optional 1x3xHxW [0,1] to build a one-sample 'real' stats\n",
        "):\n",
        "    \"\"\"\n",
        "    Use with caution. True FID needs MANY images. This provides:\n",
        "      - If real_stats given: FID(candidate vs dataset stats)\n",
        "      - Else if real_ref_img_01 given: Frechet distance between two 1-sample Gaussians (degenerate)\n",
        "      - Else returns None\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        acts = _inception_acts(x0_img_01, device)          # (1,2048)\n",
        "        mu_c = acts.mean(dim=0)\n",
        "        # one-sample covariance is zero; add tiny eps to diagonal\n",
        "        sigma_c = torch.eye(acts.shape[1], device=device) * 1e-6\n",
        "\n",
        "        if real_stats is not None:\n",
        "            mu_r = real_stats['mu']\n",
        "            sigma_r = real_stats['sigma']\n",
        "        elif real_ref_img_01 is not None:\n",
        "            acts_r = _inception_acts(real_ref_img_01, device)\n",
        "            mu_r = acts_r.mean(dim=0)\n",
        "            sigma_r = torch.eye(acts_r.shape[1], device=device) * 1e-6\n",
        "        else:\n",
        "            return None  # cannot compute any proxy\n",
        "\n",
        "        return compute_frechet_distance(mu_c, sigma_c, mu_r, sigma_r)\n",
        "\n",
        "def compute_lpips_to_ref(x0_img_m11, ref_img_m11, device):\n",
        "    \"\"\"\n",
        "    LPIPS expects [-1,1] range. Both inputs 1x3xHxW.\n",
        "    \"\"\"\n",
        "    loss_fn = get_lpips_model(device)\n",
        "    return float(loss_fn(x0_img_m11, ref_img_m11).item())\n",
        "\n",
        "def compute_mce_metric(x0_img_01, measured_magnitude, target_shape, device):\n",
        "    \"\"\"\n",
        "    Reuse your compute_mce but accepting image already in [0,1] tensor.\n",
        "    \"\"\"\n",
        "    return compute_mce(x0_img_01, measured_magnitude, target_shape=target_shape)\n",
        "\n",
        "# ===== Unsupervised helpers =====\n",
        "\n",
        "def _tv_l1(x01):\n",
        "    \"\"\"Isotropic TV on [0,1] image, averaged over batch+channels.\"\"\"\n",
        "    dx = x01[..., 1:, :] - x01[..., :-1, :]\n",
        "    dy = x01[..., :, 1:] - x01[..., :, :-1]\n",
        "    tv = dx.abs().mean() + dy.abs().mean()\n",
        "    return float(tv)\n",
        "\n",
        "@torch.no_grad()\n",
        "def _prior_eps2(model, x_t, t_long):\n",
        "    \"\"\"Mean squared epsilon prediction at level t (lower ~ more prior-favored).\"\"\"\n",
        "    eps = model(x_t, t_long)[:, :3]\n",
        "    return float(eps.pow(2).mean().item())\n",
        "\n",
        "@torch.no_grad()\n",
        "def _cycle_consistency(model, scheduler, x_t, t, x0_t, repeats=1):\n",
        "    \"\"\"\n",
        "    Re-noise x0_t back to level t with fresh noise(s) and measure how stable x0 prediction is.\n",
        "    Lower is better. Cost: repeats extra forward passes.\n",
        "    \"\"\"\n",
        "    t_long = torch.full((1,), int(t), device=x_t.device, dtype=torch.long)\n",
        "    alpha_t = scheduler.alphas_cumprod[int(t)]\n",
        "    sqrt_a = alpha_t.sqrt()\n",
        "    sqrt_1ma = (1 - alpha_t).sqrt()\n",
        "\n",
        "    errs = []\n",
        "    for _ in range(repeats):\n",
        "        z = torch.randn_like(x_t)\n",
        "        x_t_renoised = sqrt_a * x0_t + sqrt_1ma * z\n",
        "        eps2 = model(x_t_renoised, t_long)[:, :3]\n",
        "        x0_again = (x_t_renoised - sqrt_1ma * eps2) / sqrt_a\n",
        "        errs.append((x0_again - x0_t).pow(2).mean().item())\n",
        "    return float(sum(errs) / len(errs))\n",
        "\n",
        "def score_candidate(\n",
        "    x0_img_m11,                 # 1x3xHxW in [-1,1]\n",
        "    metric_cfg,                 # dict controlling metric choice & weights\n",
        "    y_mag,                      # |A x| measurement magnitude\n",
        "    target_shape,               # measurement shape (unused if using operator.forward)\n",
        "    device,\n",
        "    refs=None,                  # unused here but kept for API compatibility\n",
        "    *,\n",
        "    # extra for unsupervised terms:\n",
        "    model=None,\n",
        "    scheduler=None,\n",
        "    x_t_for_prior=None,         # the x_t tensor used to predict x0_img_m11\n",
        "    t_for_prior=None            # int timestep corresponding to x_t_for_prior\n",
        "):\n",
        "    \"\"\"\n",
        "    Returns (score_float, details_dict). Lower is better.\n",
        "    Supported modes:\n",
        "      - 'mce'\n",
        "      - 'prior_eps2'        (epsilon-norm)\n",
        "      - 'cycle'             (denoiser cycle-consistency)\n",
        "      - 'tv'\n",
        "      - 'fid'\n",
        "      - 'combo_unsup'       (any weighted combination of the above)\n",
        "    \"\"\"\n",
        "    # Ensure [0,1] for TV/MCE-of-image if needed\n",
        "    x0_img_01 = (x0_img_m11 * 0.5 + 0.5).clamp(0, 1)\n",
        "\n",
        "    mode = metric_cfg.get('mode', 'mce')\n",
        "    w_mce   = float(metric_cfg.get('w_mce', 1.0))\n",
        "    w_prior = float(metric_cfg.get('w_prior', 0.0))     # weight for prior_eps2\n",
        "    w_cycle = float(metric_cfg.get('w_cycle', 0.0))\n",
        "    w_tv    = float(metric_cfg.get('w_tv', 0.0))\n",
        "    w_fid   = float(metric_cfg.get('w_fid', 0.0))\n",
        "    cycle_repeats = int(metric_cfg.get('cycle_repeats', 1))\n",
        "\n",
        "    total = 0.0\n",
        "    parts = {}\n",
        "\n",
        "    # Data fidelity\n",
        "    if mode in ('mce', 'combo_unsup'):\n",
        "        # Use your operator-based MCE; replace with your own function if needed:\n",
        "        m = operator.forward(x0_img_m11)   # complex\n",
        "        mce = (m.abs() - y_mag).pow(2).mean().item()\n",
        "        parts['mce'] = mce\n",
        "        total += w_mce * mce\n",
        "\n",
        "    # Prior: epsilon norm (needs model, x_t, t)\n",
        "    if mode in ('prior_eps2', 'combo_unsup') and (model is not None) and (x_t_for_prior is not None) and (t_for_prior is not None):\n",
        "        t_long = torch.full((1,), int(t_for_prior), device=x_t_for_prior.device, dtype=torch.long)\n",
        "        prior = _prior_eps2(model, x_t_for_prior, t_long)\n",
        "        parts['prior_eps2'] = prior\n",
        "        total += w_prior * prior\n",
        "\n",
        "    # Cycle consistency around level t (needs model, scheduler, x_t, t)\n",
        "    if mode in ('cycle', 'combo_unsup') and (model is not None) and (scheduler is not None) and (x_t_for_prior is not None) and (t_for_prior is not None):\n",
        "        cyc = _cycle_consistency(model, scheduler, x_t_for_prior, int(t_for_prior), x0_img_m11, repeats=cycle_repeats)\n",
        "        parts['cycle'] = cyc\n",
        "        total += w_cycle * cyc\n",
        "\n",
        "    # TV on x0 (works without model)\n",
        "    if mode in ('tv', 'combo_unsup'):\n",
        "        tv = _tv_l1(x0_img_01)\n",
        "        parts['tv'] = tv\n",
        "        total += w_tv * tv\n",
        "\n",
        "    # FID / proxy FID term\n",
        "    if mode in ('fid', 'combo_unsup') and w_fid != 0.0:\n",
        "        real_stats = None\n",
        "        real_ref_01 = None\n",
        "\n",
        "        if refs is not None:\n",
        "            real_stats  = refs.get('real_stats', None)\n",
        "            # fallback: single GT image if provided\n",
        "            real_ref_01 = refs.get('real_ref_img_01', None) or refs.get('gt_img_01', None)\n",
        "\n",
        "        fid_val = compute_proxy_fid(\n",
        "            x0_img_01,\n",
        "            device=device,\n",
        "            real_stats=real_stats,\n",
        "            real_ref_img_01=real_ref_01,\n",
        "        )\n",
        "        if fid_val is None:\n",
        "            fid_val = float('inf')   # if no stats, make this branch very bad\n",
        "\n",
        "        parts['fid'] = fid_val\n",
        "        total += w_fid * fid_val\n",
        "\n",
        "    # If someone selects a single mode but prerequisites missing, make it bad (infinite)\n",
        "    if mode in ('prior_eps2', 'cycle') and total == 0.0 and not parts:\n",
        "        total = float('inf')\n",
        "\n",
        "    return float(total), {'parts': parts}\n",
        "\n",
        "\n",
        "def branch_and_select(\n",
        "    x_t,                         # current noisy sample at time t (1xCxHxW)\n",
        "    t, prev_timestep,            # integers indexing scheduler\n",
        "    model, scheduler,\n",
        "    k_branches=2,                # number of branches (>=2)\n",
        "    metric_cfg=None,             # see score_candidate()\n",
        "    device=None,\n",
        "    y_mag=None,                  # measured |A x| (magnitude), same as y_n.abs()\n",
        "    target_shape=None,\n",
        "    refs=None,                   # optional refs for LPIPS/FID\n",
        "    recompute_x0_at_prev=True    # if True, score each branch by predicting x0 at prev step (cost +k fwd passes)\n",
        "):\n",
        "    \"\"\"\n",
        "    Generate k candidates for x_{t-Δ} with different noises, score each by chosen metric, keep best.\n",
        "    Returns: x_prev_best, best_details(dict)\n",
        "    \"\"\"\n",
        "    if metric_cfg is None:\n",
        "        metric_cfg = {'mode': 'mce', 'w_mce': 1.0}\n",
        "\n",
        "    alpha_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "    sqrt_alpha_prev = alpha_prev**0.5\n",
        "    sigma_prev = (1 - alpha_prev)**0.5\n",
        "\n",
        "    # First compute x0 at current t from x_t (shared)\n",
        "    tt = (torch.ones(1, device=x_t.device, dtype=torch.long) * t)\n",
        "    with torch.no_grad():\n",
        "        # predict noise and x0 at current t\n",
        "        noise_pred = model(x_t, tt)[:, :3]\n",
        "        x0_t = (x_t - (1 - scheduler.alphas_cumprod[t])**0.5 * noise_pred) / (scheduler.alphas_cumprod[t]**0.5)\n",
        "        x0_t = x0_t.clamp(-1, 1)\n",
        "\n",
        "    # Produce k candidate x_{t-Δ}\n",
        "    x_prev_list = []\n",
        "    for _ in range(k_branches):\n",
        "        z = torch.randn_like(x_t)\n",
        "        x_prev = sqrt_alpha_prev * x0_t + sigma_prev * z\n",
        "        x_prev_list.append(x_prev)\n",
        "\n",
        "    scores = []\n",
        "    details = []\n",
        "\n",
        "    if recompute_x0_at_prev:\n",
        "        # For each candidate, evaluate score based on x0 predicted at prev step\n",
        "        for xb in x_prev_list:\n",
        "            tprev = (torch.ones(1, device=xb.device, dtype=torch.long) * max(prev_timestep, 0))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                noise_pred_prev = model(xb, tprev)[:, :3]\n",
        "                x0_prev = (xb - (1 - scheduler.alphas_cumprod[max(prev_timestep,0)]).sqrt() * noise_pred_prev) / (scheduler.alphas_cumprod[max(prev_timestep,0)].sqrt())\n",
        "                x0_prev = x0_prev.clamp(-1, 1)\n",
        "\n",
        "            s, detail = score_candidate(\n",
        "                x0_prev, metric_cfg,\n",
        "                y_mag=y_mag, target_shape=target_shape, device=device, refs=refs,\n",
        "                model=model, scheduler=scheduler, x_t_for_prior=xb, t_for_prior=int(max(prev_timestep,0))\n",
        "            )\n",
        "            scores.append(s)\n",
        "            details.append({'score': s, **detail})\n",
        "    else:\n",
        "        # Score using x0 at current t (shared), which makes branches indistinguishable for metrics like MCE.\n",
        "        # Mostly useful only if your metric depends on x_prev itself rather than x0.\n",
        "        s, part = score_candidate(\n",
        "            x0_t, metric_cfg,\n",
        "            y_mag=y_mag, target_shape=target_shape, device=device, refs=refs\n",
        "        )\n",
        "        scores = [s for _ in range(k_branches)]\n",
        "        details = [{'score': s, 'parts': part} for _ in range(k_branches)]\n",
        "\n",
        "    # Pick best\n",
        "    best_idx = int(torch.tensor(scores).argmin().item())\n",
        "    return x_prev_list[best_idx], {'best_idx': best_idx, 'scores': scores, 'details': details}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c0cd6011",
      "metadata": {
        "id": "c0cd6011"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_fid_real_stats_from_folder(\n",
        "    data_root,\n",
        "    image_ids,\n",
        "    device,\n",
        "    save_path=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Scan GT images, extract Inception features, and compute FID stats (mu, sigma).\n",
        "    - data_root: folder containing '00010.png', '00011.png', ..., etc.\n",
        "    - image_ids: list of ints, e.g. range(10, 50)\n",
        "    - device: torch.device\n",
        "    - save_path: optional .pt path to save {'mu','sigma','image_ids'}\n",
        "    \"\"\"\n",
        "    feats = []\n",
        "\n",
        "    for idx in image_ids:\n",
        "        fname = f\"{idx:05d}.png\"\n",
        "        fpath = os.path.join(data_root, fname)\n",
        "        if not os.path.exists(fpath):\n",
        "            print(f\"[WARN] GT file not found: {fpath} (skipping)\")\n",
        "            continue\n",
        "\n",
        "        img = Image.open(fpath).convert(\"RGB\")\n",
        "        # to [0,1], shape [1,3,H,W]\n",
        "        x = torch.from_numpy(np.array(img).astype(np.float32) / 255.0)  # HxWx3\n",
        "        x = x.permute(2, 0, 1).unsqueeze(0).to(device)  # 1x3xHxW\n",
        "\n",
        "        # Inception features: 1x2048\n",
        "        f = _inception_acts(x, device)  # [1, 2048]\n",
        "        feats.append(f.cpu())\n",
        "\n",
        "    if len(feats) == 0:\n",
        "        raise RuntimeError(\"No GT features collected for FID stats!\")\n",
        "\n",
        "    feats = torch.cat(feats, dim=0)  # [N, 2048]\n",
        "    N = feats.shape[0]\n",
        "    print(f\"Collected Inception features for {N} GT images.\")\n",
        "\n",
        "    # mean\n",
        "    mu = feats.mean(dim=0)  # [2048]\n",
        "\n",
        "    # unbiased covariance: (N-1) in denominator\n",
        "    diff = feats - mu.unsqueeze(0)\n",
        "    sigma = diff.t().mm(diff) / (N - 1)  # [2048, 2048]\n",
        "\n",
        "    stats = {\n",
        "        \"mu\": mu,\n",
        "        \"sigma\": sigma,\n",
        "        \"image_ids\": list(image_ids),\n",
        "    }\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(stats, save_path)\n",
        "        print(f\"Saved FID stats to {save_path}\")\n",
        "\n",
        "    return stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a4cd83cd",
      "metadata": {
        "id": "a4cd83cd",
        "outputId": "f4f676ea-e8f0-4ab5-998f-f3077ace5bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collected Inception features for 40 GT images.\n",
            "Saved FID stats to real_stats_ffhq_0010_0049.pt\n"
          ]
        }
      ],
      "source": [
        "data_root = \"data/demo_remain/\"\n",
        "image_ids = range(10, 50)  # 00010.png ... 00049.png\n",
        "script_dir = \"Phase_Retrieval_SITCOM\"  # folder of th script\n",
        "save_path  = \"real_stats_ffhq_0010_0049.pt\"\n",
        "\n",
        "real_stats = compute_fid_real_stats_from_folder(\n",
        "    data_root=data_root,\n",
        "    image_ids=image_ids,\n",
        "    device=device,\n",
        "    save_path=save_path,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "460321eb",
      "metadata": {
        "id": "460321eb"
      },
      "outputs": [],
      "source": [
        "# Path where you saved stats\n",
        "fid_stats_path = \"real_stats_ffhq_0010_0049.pt\"\n",
        "\n",
        "REAL_STATS = torch.load(fid_stats_path, map_location=device)\n",
        "REAL_STATS[\"mu\"]    = REAL_STATS[\"mu\"].to(device)\n",
        "REAL_STATS[\"sigma\"] = REAL_STATS[\"sigma\"].to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "20325159",
      "metadata": {
        "id": "20325159"
      },
      "outputs": [],
      "source": [
        "refs = {\n",
        "    \"real_stats\": REAL_STATS,        # precomputed dataset stats\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "81442c79",
      "metadata": {
        "id": "81442c79"
      },
      "outputs": [],
      "source": [
        "out = []\n",
        "n_step = 20\n",
        "scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "step_size = 1000//n_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "53483c61-94ce-4b3c-932a-71b634313ed1",
      "metadata": {
        "id": "53483c61-94ce-4b3c-932a-71b634313ed1"
      },
      "outputs": [],
      "source": [
        "dtype = torch.float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "06d0e8e1",
      "metadata": {
        "id": "06d0e8e1"
      },
      "outputs": [],
      "source": [
        "filename = f\"{12:05d}.png\"            # 00011, 00012, …, 00019 etc... i\n",
        "filepath = os.path.join(\"data/demo_remain/\", filename)\n",
        "gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "#shutil.copy(gt_img_path, os.path.join(logdir, 'gt.png'))\n",
        "ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "x = ref_numpy * 2 - 1\n",
        "x = x.transpose(2, 0, 1)\n",
        "ref_img = torch.Tensor(x).to(dtype).to(device).unsqueeze(0)\n",
        "ref_img.requires_grad = False\n",
        "#ref_img = ref_img.to(device)\n",
        "if measure_config['operator'] ['name'] == 'inpainting':\n",
        "    mask = mask\n",
        "    measurement_cond_fn = partial(cond_method.conditioning, mask=mask)\n",
        "    sample_fn = partial(sample_fn, measurement_cond_fn=measurement_cond_fn)\n",
        "\n",
        "    # Forward measurement model (Ax + n)\n",
        "    y = operator.forward(ref_img, mask=mask)\n",
        "    y_n = noiser(y)\n",
        "\n",
        "else:\n",
        "    # Forward measurement model (Ax + n)\n",
        "    y = operator.forward(ref_img)\n",
        "    y_n = noiser(y)\n",
        "    #y_n = torch.clamp(y_n,-1,1)\n",
        "#y_n.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e570ed96",
      "metadata": {
        "id": "e570ed96"
      },
      "outputs": [],
      "source": [
        "gt = (ref_img/2+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ef5e7945",
      "metadata": {
        "id": "ef5e7945"
      },
      "outputs": [],
      "source": [
        "resize_transform = torchvision.transforms.Resize((256,256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d15c8f1e",
      "metadata": {
        "id": "d15c8f1e"
      },
      "outputs": [],
      "source": [
        "def sample_terminal_xT(shape, device, scheduler):\n",
        "    aT = scheduler.alphas_cumprod[-1]\n",
        "    z  = torch.randn(shape, device=device)\n",
        "    xT = torch.randn(shape, device=device) * (aT**0.5) + z * ((1 - aT)**0.5)\n",
        "    return xT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "35595460",
      "metadata": {
        "id": "35595460"
      },
      "outputs": [],
      "source": [
        "def to01(x_m11): return (x_m11*0.5 + 0.5).clamp(0,1)\n",
        "\n",
        "y = operator.forward(ref_img); y_n = noiser(y); y_mag = y_n.abs()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "446b49c0",
      "metadata": {
        "id": "446b49c0"
      },
      "source": [
        "## Single Run Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "7dc47050",
      "metadata": {
        "id": "7dc47050",
        "outputId": "6c25da6f-95a5-4a91-8df5-bc97fa95ca88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reconstructing Image 00012.png...\n",
            "Initial MCE:,  0.0667\n",
            "Time: 950, Step 1/20, MCE: 0.037122\n",
            "Time: 900, Step 2/20, MCE: 0.100398\n",
            "Time: 850, Step 3/20, MCE: 0.071426\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1885375805.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#for k in range(1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_original_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0moptimize_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqrt_one_minus_alpha_cumprod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_prod_t\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;31m#    input= pred_original_sample * alpha_prod_t**0.5+(1-alpha_prod_t)**0.5*torch.randn(input.size()).to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-734052975.py\u001b[0m in \u001b[0;36moptimize_input\u001b[0;34m(input, sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod, t, num_steps, learning_rate)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# predict noise and x0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mnoise_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msqrt_one_minus_alpha_cumprod\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnoise_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msqrt_alpha_cumprod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Phase_Retrieval_SITCOM/guided_diffusion/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, timesteps, y)\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Phase_Retrieval_SITCOM/guided_diffusion/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimestepBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Phase_Retrieval_SITCOM/guided_diffusion/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0man\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m \u001b[0mx\u001b[0m \u001b[0mC\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \"\"\"\n\u001b[0;32m--> 303\u001b[0;31m         return checkpoint(\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         )\n",
            "\u001b[0;32m/content/Phase_Retrieval_SITCOM/guided_diffusion/nn.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(func, inputs, params, flag)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Phase_Retrieval_SITCOM/guided_diffusion/unet.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, emb)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0memb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#input = resize_transform(y_n).clone()\n",
        "# input =torch.randn((1, 3, 256, 256), device=device, dtype=dtype).clone().detach() #.requires_grad_(True)\n",
        "# noise = torch.randn(input.shape)*((1-scheduler.alphas_cumprod[-1])**0.5)\n",
        "# input = torch.tensor(input)*((scheduler.alphas_cumprod[-1])**0.5) + noise.to(device)\n",
        "input = sample_terminal_xT((1, 3, 256, 256), device, scheduler)\n",
        "\n",
        "# Clear output visualization in case didn't rerun\n",
        "out_visual = []\n",
        "measurement_errors = []\n",
        "\n",
        "# Print Initial MCE\n",
        "print(f\"Reconstructing Image {filename}...\")\n",
        "# init_mce = compute_mce(input, y_n.abs(), target_shape=y_n.shape)\n",
        "# init_mce = compute_mce((input/2+0.5).clamp(0,1), y_n.abs(), target_shape=y_n.shape)\n",
        "init_mce = compute_mce(to01(input), y_n.abs(), target_shape=y_n.shape)\n",
        "print(f\"Initial MCE:, {init_mce: .4f}\")\n",
        "\n",
        "for i, t in enumerate(scheduler.timesteps):\n",
        "        prev_timestep = t - step_size\n",
        "\n",
        "        alpha_prod_t = scheduler.alphas_cumprod[t]\n",
        "        alpha_prod_t_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "\n",
        "        beta_prod_t = 1 - alpha_prod_t\n",
        "        sqrt_one_minus_alpha_cumprod = beta_prod_t**0.5\n",
        "\n",
        "\n",
        "        #for k in range(1):\n",
        "        input, pred_original_sample, noise_pred= optimize_input(input.clone(), sqrt_one_minus_alpha_cumprod, alpha_prod_t**0.5, t, num_steps=20, learning_rate=0.1)\n",
        "        #    input= pred_original_sample * alpha_prod_t**0.5+(1-alpha_prod_t)**0.5*torch.randn(input.size()).to(device)\n",
        "\n",
        "        phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "\n",
        "        # Compute measurement error\n",
        "        mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "        measurement_errors.append(mce)\n",
        "\n",
        "        ## Trying this: Multi Branches\n",
        "        # --- Branch & Select update ---\n",
        "        metric_cfg = {\n",
        "            'mode': 'fid',   # 'mce' | 'lpips' | 'fid' | 'combo'\n",
        "            # 'w_mce': 1.0,\n",
        "            # 'w_lpips': 0.0,\n",
        "            'w_fid': 1.0\n",
        "        }\n",
        "        refs = {\n",
        "            # Optional helpers for LPIPS/FID:\n",
        "            \"real_stats\": REAL_STATS,\n",
        "            # 'gt_img_m11': ref_img           # if you want LPIPS to GT (in [-1,1])\n",
        "            # 'gt_img_01' : (ref_img*0.5+0.5) # if you want a proxy FID vs single GT image (in [0,1])\n",
        "            # 'real_stats': {'mu': mu_r, 'sigma': sigma_r}  # precomputed dataset stats on device (recommended if you insist on FID)\n",
        "        }\n",
        "\n",
        "        input, branch_info = branch_and_select(\n",
        "            x_t=input,\n",
        "            t=int(t),\n",
        "            prev_timestep=int(prev_timestep),\n",
        "            model=model,\n",
        "            scheduler=scheduler,\n",
        "            k_branches=2,                 # <-- make this >1 to enable branching\n",
        "            metric_cfg=metric_cfg,\n",
        "            device=device,\n",
        "            y_mag=y_n.abs(),\n",
        "            target_shape=y_n.shape,\n",
        "            refs=refs,\n",
        "            recompute_x0_at_prev=True     # better selection; costs +k forward passes\n",
        "        )\n",
        "\n",
        "        '''input = pred_original_sample * alpha_prod_t_prev**0.5+(1-alpha_prod_t_prev)**0.5*torch.randn(input.size()).to(device)'''\n",
        "\n",
        "        print(f\"Time: {t}, Step {i+1}/{n_step}, MCE: {mce:.6f}\")\n",
        "\n",
        "\n",
        "input = (input/2+0.5).clamp(0, 1)\n",
        "phase_image = (pred_original_sample/2+0.5).clamp(0, 1)\n",
        "#input = (input + 1) / 2\n",
        "phase_image = phase_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "psnr_value1 = compute_psnr(phase_image, np.array(gt.cpu().detach().numpy()[0].transpose(1,2,0)))\n",
        "print(f\"PSNR: {psnr_value1} dB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c5257d",
      "metadata": {
        "id": "e0c5257d"
      },
      "outputs": [],
      "source": [
        "# Function definitions?\n",
        "\n",
        "def run_og():\n",
        "    input = sample_terminal_xT((1, 3, 256, 256), device, scheduler)\n",
        "\n",
        "    # Clear output visualization in case didn't rerun\n",
        "    out_visual = []\n",
        "    measurement_errors = []\n",
        "\n",
        "    # Print Initial MCE\n",
        "    print(f\"Reconstructing Image {filename}...\")\n",
        "    # init_mce = compute_mce(input, y_n.abs(), target_shape=y_n.shape)\n",
        "    # init_mce = compute_mce((input/2+0.5).clamp(0,1), y_n.abs(), target_shape=y_n.shape)\n",
        "    init_mce = compute_mce(to01(input), y_n.abs(), target_shape=y_n.shape)\n",
        "    # print(f\"Initial MCE:, {init_mce: .4f}\")\n",
        "\n",
        "    for i, t in enumerate(scheduler.timesteps):\n",
        "            prev_timestep = t - step_size\n",
        "\n",
        "            alpha_prod_t = scheduler.alphas_cumprod[t]\n",
        "            alpha_prod_t_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "\n",
        "            beta_prod_t = 1 - alpha_prod_t\n",
        "            sqrt_one_minus_alpha_cumprod = beta_prod_t**0.5\n",
        "\n",
        "\n",
        "            #for k in range(1):\n",
        "            input, pred_original_sample, noise_pred= optimize_input(input.clone(), sqrt_one_minus_alpha_cumprod, alpha_prod_t**0.5, t, num_steps=20, learning_rate=0.1)\n",
        "            #    input= pred_original_sample * alpha_prod_t**0.5+(1-alpha_prod_t)**0.5*torch.randn(input.size()).to(device)\n",
        "\n",
        "            phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "\n",
        "            # Compute measurement error with correct shape\n",
        "            mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "            measurement_errors.append(mce)\n",
        "\n",
        "            ## Trying this: Multi Branches\n",
        "            # --- Branch & Select update ---\n",
        "            '''metric_cfg = {\n",
        "                'mode': 'mce',   # 'mce' | 'lpips' | 'fid' | 'combo'\n",
        "                'w_mce': 1.0,\n",
        "                # 'w_lpips': 0.0,\n",
        "                # 'w_fid': 0.0\n",
        "            }\n",
        "            refs = {\n",
        "                # Optional helpers for LPIPS/FID:\n",
        "                # 'gt_img_m11': ref_img           # if you want LPIPS to GT (in [-1,1])\n",
        "                # 'gt_img_01' : (ref_img*0.5+0.5) # if you want a proxy FID vs single GT image (in [0,1])\n",
        "                # 'real_stats': {'mu': mu_r, 'sigma': sigma_r}  # precomputed dataset stats on device (recommended if you insist on FID)\n",
        "            }'''\n",
        "            metric_cfg = {'mode': 'fid', 'w_fid': 1.0}\n",
        "\n",
        "\n",
        "\n",
        "            input, branch_info = branch_and_select(\n",
        "                x_t=input,\n",
        "                t=int(t),\n",
        "                prev_timestep=int(prev_timestep),\n",
        "                model=model,\n",
        "                scheduler=scheduler,\n",
        "                k_branches=2,                 # <-- make this >1 to enable branching\n",
        "                metric_cfg=metric_cfg,\n",
        "                device=device,\n",
        "                y_mag=y_n.abs(),\n",
        "                target_shape=y_n.shape,\n",
        "                refs=refs,\n",
        "                recompute_x0_at_prev=True     # better selection; costs +k forward passes\n",
        "            )\n",
        "\n",
        "            '''input = pred_original_sample * alpha_prod_t_prev**0.5+(1-alpha_prod_t_prev)**0.5*torch.randn(input.size()).to(device)'''\n",
        "\n",
        "            print(f\"Time: {t}, Step {i+1}/{n_step}, MCE: {mce:.6f}\")\n",
        "\n",
        "\n",
        "    input = (input/2+0.5).clamp(0, 1)\n",
        "    phase_image = (pred_original_sample/2+0.5).clamp(0, 1)\n",
        "    #input = (input + 1) / 2\n",
        "    phase_image = phase_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "    psnr_value1 = compute_psnr(phase_image, np.array(gt.cpu().detach().numpy()[0].transpose(1,2,0)))\n",
        "    print(f\"PSNR: {psnr_value1} dB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99400a3d",
      "metadata": {
        "id": "99400a3d"
      },
      "outputs": [],
      "source": [
        "for _ in range(10):\n",
        "    run_og()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff7ec45",
      "metadata": {
        "id": "9ff7ec45"
      },
      "source": [
        "## Multi-Metrics Testing ##"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f85eb85",
      "metadata": {
        "id": "3f85eb85"
      },
      "source": [
        "## Run def run_og_single, create METRIC_CFGS_OG, run def sweep_og_metrics, then run main\n",
        "\n",
        "supporting 'modes' in METRIC_CFGS_OG:\n",
        "\n",
        "      - 'mce'\n",
        "      - 'prior_eps2'        (epsilon-norm)\n",
        "      - 'cycle'             (denoiser cycle-consistency)\n",
        "      - 'tv'\n",
        "      - 'fid'\n",
        "      - 'combo_unsup'       (any weighted combination of the above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b572f6b1",
      "metadata": {
        "id": "b572f6b1"
      },
      "outputs": [],
      "source": [
        "def run_og_single(metric_cfg, k_branches=2, num_steps=20, lr=0.1):\n",
        "    \"\"\"\n",
        "    One reconstruction run, as close as possible to your original run_og,\n",
        "    but with:\n",
        "      - metric_cfg: dict for branch_and_select\n",
        "      - k_branches: number of branches per step\n",
        "    Uses global: filename, gt, y_n, scheduler, step_size, model, device.\n",
        "    Returns: dict with PSNR, final MCE, and the full MCE trace.\n",
        "    \"\"\"\n",
        "    # Sample x_T exactly as in your reference code\n",
        "    input = sample_terminal_xT((1, 3, 256, 256), device, scheduler)\n",
        "\n",
        "    # Clear output visualization in case didn't rerun\n",
        "    out_visual = []\n",
        "    measurement_errors = []\n",
        "\n",
        "    print(f\"\\nReconstructing Image {filename} with metric={metric_cfg.get('mode')} | K={k_branches}\")\n",
        "    init_mce = compute_mce(to01(input), y_n.abs(), target_shape=y_n.shape)\n",
        "    print(f\"Initial MCE: {init_mce:.4f}\")\n",
        "    measurement_errors.append(init_mce)\n",
        "\n",
        "    # refs = None if not FID\n",
        "    # refs = {\"real_stats\": REAL_STATS,}\n",
        "    refs = None\n",
        "\n",
        "    # DDIM / scheduler timesteps loop\n",
        "    for i, t in enumerate(scheduler.timesteps):\n",
        "        prev_timestep = t - step_size\n",
        "\n",
        "        alpha_prod_t = scheduler.alphas_cumprod[t]\n",
        "        alpha_prod_t_prev = (\n",
        "            scheduler.alphas_cumprod[prev_timestep]\n",
        "            if prev_timestep >= 0 else\n",
        "            scheduler.alphas_cumprod[0]\n",
        "        )\n",
        "\n",
        "        beta_prod_t = 1 - alpha_prod_t\n",
        "        sqrt_one_minus_alpha_cumprod = beta_prod_t**0.5\n",
        "\n",
        "        # 1) inner optimization (unchanged)\n",
        "        input, pred_original_sample, noise_pred = optimize_input(\n",
        "            input.clone(),\n",
        "            sqrt_one_minus_alpha_cumprod,\n",
        "            alpha_prod_t**0.5,\n",
        "            int(t),\n",
        "            num_steps=num_steps,\n",
        "            learning_rate=lr,\n",
        "        )\n",
        "\n",
        "        # 2) log MCE via your manual path\n",
        "        phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "        mce_val = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "        measurement_errors.append(mce_val)\n",
        "\n",
        "        # 3) branch & select using the given metric_cfg\n",
        "        input, branch_info = branch_and_select(\n",
        "            x_t=input,\n",
        "            t=int(t),\n",
        "            prev_timestep=int(prev_timestep),\n",
        "            model=model,\n",
        "            scheduler=scheduler,\n",
        "            k_branches=int(k_branches),\n",
        "            metric_cfg=metric_cfg,\n",
        "            device=device,\n",
        "            y_mag=y_n.abs(),\n",
        "            target_shape=y_n.shape,\n",
        "            refs=refs,\n",
        "            recompute_x0_at_prev=True\n",
        "        )\n",
        "\n",
        "        # pretty print branch scores for debugging\n",
        "        scores = branch_info['scores']\n",
        "        best   = branch_info['best_idx']\n",
        "        score_line = \" | \".join([f\"B{j}:{scores[j]:.6f}\" for j in range(len(scores))])\n",
        "        print(f\"[t={int(t):>3}] Branch scores: {score_line}  -> pick B{best} | MCE={mce_val:.6f}\")\n",
        "\n",
        "    # End of steps: compute final image & PSNR (same as your reference)\n",
        "    input_final = (input / 2 + 0.5).clamp(0, 1)\n",
        "    x0_final    = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "    x0_np       = x0_final.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "    psnr_value = compute_psnr(\n",
        "        x0_np,\n",
        "        np.array(gt.cpu().detach().numpy()[0].transpose(1, 2, 0))\n",
        "    )\n",
        "    final_mce = float(measurement_errors[-1])\n",
        "\n",
        "    print(f\"Final PSNR={psnr_value:.3f} dB | Final MCE={final_mce:.6f}\")\n",
        "\n",
        "    return {\n",
        "        'psnr': float(psnr_value),\n",
        "        'final_mce': final_mce,\n",
        "        'mce_trace': [float(m) for m in measurement_errors],\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc79b8ac",
      "metadata": {
        "id": "bc79b8ac"
      },
      "outputs": [],
      "source": [
        "# This needs to be after METRIC_CFGS_OG defined\n",
        "\n",
        "def sweep_og_metrics(\n",
        "    metric_cfgs=METRIC_CFGS_OG,\n",
        "    k_branches_list=(2,),\n",
        "    num_runs=10,\n",
        "    num_steps=20,\n",
        "    lr=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    OG-style sweep:\n",
        "      - no image/measurement setup inside (assumes filename, gt, y_n, scheduler, step_size ready)\n",
        "      - loops over metric_cfgs and K, runs run_og_single many times\n",
        "      - prints summary per (metric, K)\n",
        "    Returns: list of result dicts for further inspection.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "\n",
        "    for k in k_branches_list:\n",
        "        for m in metric_cfgs:\n",
        "            cfg = dict(m['cfg'])           # copy to avoid accidental mutation\n",
        "            cfg['name'] = m['name']\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(f\"OG SWEEP: metric={cfg['name']} | K={k} | runs={num_runs}\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            psnrs = []\n",
        "            mces  = []\n",
        "\n",
        "            for run_idx in range(num_runs):\n",
        "                print(f\"\\n--- Run {run_idx+1}/{num_runs} ---\")\n",
        "                res = run_og_single(\n",
        "                    metric_cfg=cfg,\n",
        "                    k_branches=k,\n",
        "                    num_steps=num_steps,\n",
        "                    lr=lr,\n",
        "                )\n",
        "                psnrs.append(res['psnr'])\n",
        "                mces.append(res['final_mce'])\n",
        "\n",
        "            psnrs = np.array(psnrs, dtype=float)\n",
        "            mces  = np.array(mces, dtype=float)\n",
        "\n",
        "            mean_psnr = float(psnrs.mean())\n",
        "            std_psnr  = float(psnrs.std())\n",
        "            mean_mce  = float(mces.mean())\n",
        "            std_mce   = float(mces.std())\n",
        "\n",
        "            best_psnr_idx   = int(psnrs.argmax())\n",
        "            worst_psnr_idx  = int(psnrs.argmin())\n",
        "            best_mce_idx    = int(mces.argmin())\n",
        "            worst_mce_idx   = int(mces.argmax())\n",
        "\n",
        "            best_psnr       = float(psnrs[best_psnr_idx])\n",
        "            best_psnr_mce   = float(mces[best_psnr_idx])\n",
        "            worst_psnr      = float(psnrs[worst_psnr_idx])\n",
        "            worst_psnr_mce  = float(mces[worst_psnr_idx])\n",
        "\n",
        "            best_mce        = float(mces[best_mce_idx])\n",
        "            best_mce_psnr   = float(psnrs[best_mce_idx])\n",
        "            worst_mce       = float(mces[worst_mce_idx])\n",
        "            worst_mce_psnr  = float(psnrs[worst_mce_idx])\n",
        "\n",
        "            print(\"\\nSummary for metric={} | K={}\".format(cfg['name'], k))\n",
        "            print(f\"  PSNR  mean±std  = {mean_psnr:.3f} ± {std_psnr:.3f} dB\")\n",
        "            print(f\"  MCE   mean±std  = {mean_mce:.6f} ± {std_mce:.6f}\")\n",
        "            print(f\"  Best  PSNR run  = {best_psnr_idx+1} \"\n",
        "                  f\"(PSNR={best_psnr:.3f}, MCE={best_psnr_mce:.6f})\")\n",
        "            print(f\"  Worst PSNR run  = {worst_psnr_idx+1} \"\n",
        "                  f\"(PSNR={worst_psnr:.3f}, MCE={worst_psnr_mce:.6f})\")\n",
        "            print(f\"  Best  MCE  run  = {best_mce_idx+1} \"\n",
        "                  f\"(MCE={best_mce:.6f}, PSNR={best_mce_psnr:.3f})\")\n",
        "            print(f\"  Worst MCE  run  = {worst_mce_idx+1} \"\n",
        "                  f\"(MCE={worst_mce:.6f}, PSNR={worst_mce_psnr:.3f})\")\n",
        "\n",
        "\n",
        "            all_results.append({\n",
        "                'metric_name': cfg['name'],\n",
        "                'metric_cfg':  cfg,\n",
        "                'k_branches':  k,\n",
        "                'num_runs':    num_runs,\n",
        "                'psnrs':       psnrs,\n",
        "                'mces':        mces,\n",
        "                'mean_psnr':   mean_psnr,\n",
        "                'std_psnr':    std_psnr,\n",
        "                'mean_mce':    mean_mce,\n",
        "                'std_mce':     std_mce,\n",
        "\n",
        "                'best_psnr_idx':   best_psnr_idx,\n",
        "                'worst_psnr_idx':  worst_psnr_idx,\n",
        "                'best_mce_idx':    best_mce_idx,\n",
        "                'worst_mce_idx':   worst_mce_idx,\n",
        "\n",
        "                'best_psnr':       best_psnr,\n",
        "                'best_psnr_mce':   best_psnr_mce,\n",
        "                'worst_psnr':      worst_psnr,\n",
        "                'worst_psnr_mce':  worst_psnr_mce,\n",
        "\n",
        "                'best_mce':        best_mce,\n",
        "                'best_mce_psnr':   best_mce_psnr,\n",
        "                'worst_mce':       worst_mce,\n",
        "                'worst_mce_psnr':  worst_mce_psnr,\n",
        "            })\n",
        "\n",
        "\n",
        "    return all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a35b3c",
      "metadata": {
        "id": "34a35b3c"
      },
      "outputs": [],
      "source": [
        "METRIC_CFGS_OG = [{'name': 'fid',\n",
        "     'cfg':  {'mode': 'fid', 'w_fid': 1.0}}]\n",
        "\n",
        "results_og = sweep_og_metrics(\n",
        "    metric_cfgs=METRIC_CFGS_OG,\n",
        "    k_branches_list=(2,),\n",
        "    num_runs=10,\n",
        "    num_steps=20,\n",
        "    lr=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51c64d51",
      "metadata": {
        "id": "51c64d51"
      },
      "outputs": [],
      "source": [
        "# Same style as the master loop METRIC_CFGS:\n",
        "METRIC_CFGS_OG = [\n",
        "    # (A) pure data fidelity (baseline)\n",
        "    {'name': 'mce',\n",
        "     'cfg':  {'mode': 'mce', 'w_mce': 1.0}},\n",
        "\n",
        "    # (B) MCE + tiny epsilon prior (uncomment if you want to test it)\n",
        "    {'name': 'mce+eps1e-3',\n",
        "      'cfg': {'mode': 'combo_unsup', 'w_mce': 1.0, 'w_prior': 1e-3,\n",
        "              'w_cycle': 0.0, 'w_tv': 0.0}},\n",
        "\n",
        "    # (C) MCE + cycle consistency\n",
        "     {'name': 'mce+cycle1e-2',\n",
        "      'cfg': {'mode': 'combo_unsup', 'w_mce': 1.0, 'w_cycle': 1e-2,\n",
        "              'cycle_repeats': 1, 'w_prior': 0.0, 'w_tv': 0.0}},\n",
        "\n",
        "    # (D) MCE + TV\n",
        "     {'name': 'mce+tv1e-3',\n",
        "      'cfg': {'mode': 'combo_unsup', 'w_mce': 1.0, 'w_tv': 1e-3}},\n",
        "\n",
        "    # (E) all three, conservative weights\n",
        "     {'name': 'mce+eps1e-3+cycle1e-2+tv1e-3',\n",
        "      'cfg': {'mode': 'combo_unsup',\n",
        "              'w_mce': 1.0,\n",
        "              'w_prior': 1e-3,\n",
        "              'w_cycle': 1e-2, 'cycle_repeats': 1,\n",
        "              'w_tv': 1e-3}},\n",
        "]\n",
        "\n",
        "def sweep_og_metrics(\n",
        "    metric_cfgs=METRIC_CFGS_OG,\n",
        "    k_branches_list=(2,),\n",
        "    num_runs=10,\n",
        "    num_steps=20,\n",
        "    lr=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    OG-style sweep:\n",
        "      - no image/measurement setup inside (assumes filename, gt, y_n, scheduler, step_size ready)\n",
        "      - loops over metric_cfgs and K, runs run_og_single many times\n",
        "      - prints summary per (metric, K)\n",
        "    Returns: list of result dicts for further inspection.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "\n",
        "    for k in k_branches_list:\n",
        "        for m in metric_cfgs:\n",
        "            cfg = dict(m['cfg'])           # copy to avoid accidental mutation\n",
        "            cfg['name'] = m['name']\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(f\"OG SWEEP: metric={cfg['name']} | K={k} | runs={num_runs}\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            psnrs = []\n",
        "            mces  = []\n",
        "\n",
        "            for run_idx in range(num_runs):\n",
        "                print(f\"\\n--- Run {run_idx+1}/{num_runs} ---\")\n",
        "                res = run_og_single(\n",
        "                    metric_cfg=cfg,\n",
        "                    k_branches=k,\n",
        "                    num_steps=num_steps,\n",
        "                    lr=lr,\n",
        "                )\n",
        "                psnrs.append(res['psnr'])\n",
        "                mces.append(res['final_mce'])\n",
        "\n",
        "            psnrs = np.array(psnrs, dtype=float)\n",
        "            mces  = np.array(mces, dtype=float)\n",
        "\n",
        "            mean_psnr = float(psnrs.mean())\n",
        "            std_psnr  = float(psnrs.std())\n",
        "            mean_mce  = float(mces.mean())\n",
        "            std_mce   = float(mces.std())\n",
        "\n",
        "            best_psnr_idx   = int(psnrs.argmax())\n",
        "            worst_psnr_idx  = int(psnrs.argmin())\n",
        "            best_mce_idx    = int(mces.argmin())\n",
        "            worst_mce_idx   = int(mces.argmax())\n",
        "\n",
        "            best_psnr       = float(psnrs[best_psnr_idx])\n",
        "            best_psnr_mce   = float(mces[best_psnr_idx])\n",
        "            worst_psnr      = float(psnrs[worst_psnr_idx])\n",
        "            worst_psnr_mce  = float(mces[worst_psnr_idx])\n",
        "\n",
        "            best_mce        = float(mces[best_mce_idx])\n",
        "            best_mce_psnr   = float(psnrs[best_mce_idx])\n",
        "            worst_mce       = float(mces[worst_mce_idx])\n",
        "            worst_mce_psnr  = float(psnrs[worst_mce_idx])\n",
        "\n",
        "            print(\"\\nSummary for metric={} | K={}\".format(cfg['name'], k))\n",
        "            print(f\"  PSNR  mean±std  = {mean_psnr:.3f} ± {std_psnr:.3f} dB\")\n",
        "            print(f\"  MCE   mean±std  = {mean_mce:.6f} ± {std_mce:.6f}\")\n",
        "            print(f\"  Best  PSNR run  = {best_psnr_idx+1} \"\n",
        "                  f\"(PSNR={best_psnr:.3f}, MCE={best_psnr_mce:.6f})\")\n",
        "            print(f\"  Worst PSNR run  = {worst_psnr_idx+1} \"\n",
        "                  f\"(PSNR={worst_psnr:.3f}, MCE={worst_psnr_mce:.6f})\")\n",
        "            print(f\"  Best  MCE  run  = {best_mce_idx+1} \"\n",
        "                  f\"(MCE={best_mce:.6f}, PSNR={best_mce_psnr:.3f})\")\n",
        "            print(f\"  Worst MCE  run  = {worst_mce_idx+1} \"\n",
        "                  f\"(MCE={worst_mce:.6f}, PSNR={worst_mce_psnr:.3f})\")\n",
        "\n",
        "\n",
        "            all_results.append({\n",
        "                'metric_name': cfg['name'],\n",
        "                'metric_cfg':  cfg,\n",
        "                'k_branches':  k,\n",
        "                'num_runs':    num_runs,\n",
        "                'psnrs':       psnrs,\n",
        "                'mces':        mces,\n",
        "                'mean_psnr':   mean_psnr,\n",
        "                'std_psnr':    std_psnr,\n",
        "                'mean_mce':    mean_mce,\n",
        "                'std_mce':     std_mce,\n",
        "\n",
        "                'best_psnr_idx':   best_psnr_idx,\n",
        "                'worst_psnr_idx':  worst_psnr_idx,\n",
        "                'best_mce_idx':    best_mce_idx,\n",
        "                'worst_mce_idx':   worst_mce_idx,\n",
        "\n",
        "                'best_psnr':       best_psnr,\n",
        "                'best_psnr_mce':   best_psnr_mce,\n",
        "                'worst_psnr':      worst_psnr,\n",
        "                'worst_psnr_mce':  worst_psnr_mce,\n",
        "\n",
        "                'best_mce':        best_mce,\n",
        "                'best_mce_psnr':   best_mce_psnr,\n",
        "                'worst_mce':       worst_mce,\n",
        "                'worst_mce_psnr':  worst_mce_psnr,\n",
        "            })\n",
        "\n",
        "\n",
        "    return all_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e72a1fe",
      "metadata": {
        "id": "1e72a1fe"
      },
      "outputs": [],
      "source": [
        "results_og = sweep_og_metrics(\n",
        "    metric_cfgs=METRIC_CFGS_OG,\n",
        "    k_branches_list=(2,),\n",
        "    num_runs=10,\n",
        "    num_steps=20,\n",
        "    lr=0.1,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea8297e4",
      "metadata": {
        "id": "ea8297e4"
      },
      "outputs": [],
      "source": [
        "# Same style as the master loop METRIC_CFGS:\n",
        "METRIC_CFGS_OG = [\n",
        "    # (A) pure data fidelity (baseline)\n",
        "    {'name': 'mce',\n",
        "     'cfg':  {'mode': 'mce', 'w_mce': 1.0}},\n",
        "\n",
        "    # (B) tiny epsilon norm\n",
        "    {'name': 'eps1e-3',\n",
        "      'cfg': {'mode': 'prior_eps2', 'w_mce': 0.0, 'w_prior': 1e-3,\n",
        "              'w_cycle': 0.0, 'w_tv': 0.0}},\n",
        "\n",
        "    # (C) cycle consistency\n",
        "     {'name': 'cycle1e-2',\n",
        "      'cfg': {'mode': 'cycle', 'w_mce': 0.0, 'w_cycle': 1e-2,\n",
        "              'cycle_repeats': 1, 'w_prior': 0.0, 'w_tv': 0.0}},\n",
        "\n",
        "    # (D) TV\n",
        "     {'name': 'tv',\n",
        "      'cfg': {'mode': 'tv1e-3', 'w_mce': 0.0, 'w_tv': 1e-3}},\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0021da4b",
      "metadata": {
        "id": "0021da4b"
      },
      "outputs": [],
      "source": [
        "def sweep_og_metrics(\n",
        "    metric_cfgs=METRIC_CFGS_OG,\n",
        "    k_branches_list=(2,),\n",
        "    num_runs=10,\n",
        "    num_steps=20,\n",
        "    lr=0.1\n",
        "):\n",
        "    \"\"\"\n",
        "    OG-style sweep:\n",
        "      - no image/measurement setup inside (assumes filename, gt, y_n, scheduler, step_size ready)\n",
        "      - loops over metric_cfgs and K, runs run_og_single many times\n",
        "      - prints summary per (metric, K)\n",
        "    Returns: list of result dicts for further inspection.\n",
        "    \"\"\"\n",
        "    all_results = []\n",
        "\n",
        "    for k in k_branches_list:\n",
        "        for m in metric_cfgs:\n",
        "            cfg = dict(m['cfg'])           # copy to avoid accidental mutation\n",
        "            cfg['name'] = m['name']\n",
        "\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "            print(f\"OG SWEEP: metric={cfg['name']} | K={k} | runs={num_runs}\")\n",
        "            print(\"=\"*80)\n",
        "\n",
        "            psnrs = []\n",
        "            mces  = []\n",
        "\n",
        "            for run_idx in range(num_runs):\n",
        "                print(f\"\\n--- Run {run_idx+1}/{num_runs} ---\")\n",
        "                res = run_og_single(\n",
        "                    metric_cfg=cfg,\n",
        "                    k_branches=k,\n",
        "                    num_steps=num_steps,\n",
        "                    lr=lr,\n",
        "                )\n",
        "                psnrs.append(res['psnr'])\n",
        "                mces.append(res['final_mce'])\n",
        "\n",
        "            psnrs = np.array(psnrs, dtype=float)\n",
        "            mces  = np.array(mces, dtype=float)\n",
        "\n",
        "            mean_psnr = float(psnrs.mean())\n",
        "            std_psnr  = float(psnrs.std())\n",
        "            mean_mce  = float(mces.mean())\n",
        "            std_mce   = float(mces.std())\n",
        "\n",
        "            best_psnr_idx   = int(psnrs.argmax())\n",
        "            worst_psnr_idx  = int(psnrs.argmin())\n",
        "            best_mce_idx    = int(mces.argmin())\n",
        "            worst_mce_idx   = int(mces.argmax())\n",
        "\n",
        "            best_psnr       = float(psnrs[best_psnr_idx])\n",
        "            best_psnr_mce   = float(mces[best_psnr_idx])\n",
        "            worst_psnr      = float(psnrs[worst_psnr_idx])\n",
        "            worst_psnr_mce  = float(mces[worst_psnr_idx])\n",
        "\n",
        "            best_mce        = float(mces[best_mce_idx])\n",
        "            best_mce_psnr   = float(psnrs[best_mce_idx])\n",
        "            worst_mce       = float(mces[worst_mce_idx])\n",
        "            worst_mce_psnr  = float(psnrs[worst_mce_idx])\n",
        "\n",
        "            print(\"\\nSummary for metric={} | K={}\".format(cfg['name'], k))\n",
        "            print(f\"  PSNR  mean±std  = {mean_psnr:.3f} ± {std_psnr:.3f} dB\")\n",
        "            print(f\"  MCE   mean±std  = {mean_mce:.6f} ± {std_mce:.6f}\")\n",
        "            print(f\"  Best  PSNR run  = {best_psnr_idx+1} \"\n",
        "                  f\"(PSNR={best_psnr:.3f}, MCE={best_psnr_mce:.6f})\")\n",
        "            print(f\"  Worst PSNR run  = {worst_psnr_idx+1} \"\n",
        "                  f\"(PSNR={worst_psnr:.3f}, MCE={worst_psnr_mce:.6f})\")\n",
        "            print(f\"  Best  MCE  run  = {best_mce_idx+1} \"\n",
        "                  f\"(MCE={best_mce:.6f}, PSNR={best_mce_psnr:.3f})\")\n",
        "            print(f\"  Worst MCE  run  = {worst_mce_idx+1} \"\n",
        "                  f\"(MCE={worst_mce:.6f}, PSNR={worst_mce_psnr:.3f})\")\n",
        "\n",
        "\n",
        "            all_results.append({\n",
        "                'metric_name': cfg['name'],\n",
        "                'metric_cfg':  cfg,\n",
        "                'k_branches':  k,\n",
        "                'num_runs':    num_runs,\n",
        "                'psnrs':       psnrs,\n",
        "                'mces':        mces,\n",
        "                'mean_psnr':   mean_psnr,\n",
        "                'std_psnr':    std_psnr,\n",
        "                'mean_mce':    mean_mce,\n",
        "                'std_mce':     std_mce,\n",
        "\n",
        "                'best_psnr_idx':   best_psnr_idx,\n",
        "                'worst_psnr_idx':  worst_psnr_idx,\n",
        "                'best_mce_idx':    best_mce_idx,\n",
        "                'worst_mce_idx':   worst_mce_idx,\n",
        "\n",
        "                'best_psnr':       best_psnr,\n",
        "                'best_psnr_mce':   best_psnr_mce,\n",
        "                'worst_psnr':      worst_psnr,\n",
        "                'worst_psnr_mce':  worst_psnr_mce,\n",
        "\n",
        "                'best_mce':        best_mce,\n",
        "                'best_mce_psnr':   best_mce_psnr,\n",
        "                'worst_mce':       worst_mce,\n",
        "                'worst_mce_psnr':  worst_mce_psnr,\n",
        "            })\n",
        "\n",
        "\n",
        "    return all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce4a1d3",
      "metadata": {
        "id": "5ce4a1d3"
      },
      "outputs": [],
      "source": [
        "results_og = sweep_og_metrics(\n",
        "    metric_cfgs=METRIC_CFGS_OG,\n",
        "    k_branches_list=(2,),\n",
        "    num_runs=10,\n",
        "    num_steps=20,\n",
        "    lr=0.1,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbff22f0",
      "metadata": {
        "id": "cbff22f0"
      },
      "source": [
        "## 2 Branches MCE\n",
        "![image.png](attachment:image.png)\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n",
        "## 4 Branches MCE\n",
        "![image-4.png](attachment:image-4.png)\n",
        "![image-3.png](attachment:image-3.png)\n",
        "\n",
        "## 8 Branches MCE\n",
        "![image-5.png](attachment:image-5.png)\n",
        "![image-6.png](attachment:image-6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22111afa",
      "metadata": {
        "id": "22111afa"
      },
      "outputs": [],
      "source": [
        "psnr_values = []\n",
        "for i in range(num_runs):\n",
        "    #plt.imshow(run_results[i])\n",
        "    psnr_value = compute_psnr(np.array(run_results[i]), np.array(gt.cpu().detach().numpy()[0].transpose(1,2,0)))\n",
        "    psnr_values.append(psnr_value)\n",
        "    print(f\"After diffusion PSNR: {psnr_value} dB, MCE: {mce_results[i]: .4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aceb1501",
      "metadata": {
        "id": "aceb1501"
      },
      "outputs": [],
      "source": [
        "plt.hist(psnr_values, bins = 30, alpha = 0.8, edgecolor = 'black')\n",
        "plt.xlabel(\"PSNR (dB)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(f\"Distribution of PSNR Values on {num_runs} Runs of Image {filename} with Random Input\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef69be83",
      "metadata": {
        "id": "ef69be83"
      },
      "source": [
        "## Make one file for multi run testing ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a567b9",
      "metadata": {
        "id": "b5a567b9"
      },
      "outputs": [],
      "source": [
        "import os, time, json, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "def _make_step_labels(scheduler, include_init=True):\n",
        "    \"\"\"\n",
        "    Build labels like: ['initial', f\"t{t}\", ..., 't0'] matching scheduler.timesteps.\n",
        "    \"\"\"\n",
        "    labels = []\n",
        "    if include_init:\n",
        "        labels.append(\"initial\")\n",
        "    # timesteps is typically descending (e.g., [999, 979, ...])\n",
        "    for t in list(scheduler.timesteps):\n",
        "        labels.append(f\"t{int(t)}\")\n",
        "    return labels\n",
        "\n",
        "class DMRunRecorder:\n",
        "    \"\"\"\n",
        "    Accumulates per-run traces and PSNRs for one image,\n",
        "    then computes per-image aggregates and returns tidy + wide DataFrames.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_id, scheduler):\n",
        "        self.image_id = image_id\n",
        "        self.scheduler = scheduler\n",
        "        self.step_labels = _make_step_labels(scheduler, include_init=True)\n",
        "        self.num_steps = len(self.step_labels)  # initial + len(timesteps)\n",
        "        self._per_run_mce_traces = []  # list of list[float] length == num_steps\n",
        "        self._per_run_final_psnr = []  # list[float]\n",
        "        self._per_run_final_mce  = []  # list[float]\n",
        "\n",
        "    def record_run(self, init_mce, mce_trace_per_step, final_psnr):\n",
        "        \"\"\"\n",
        "        init_mce: float\n",
        "        mce_trace_per_step: list of floats for *each diffusion step in order of scheduler.timesteps*.\n",
        "            We'll prepend init_mce so final length is num_steps.\n",
        "        final_psnr: float\n",
        "        \"\"\"\n",
        "        assert isinstance(mce_trace_per_step, (list, tuple)), \"mce_trace_per_step must be a list\"\n",
        "        trace = [float(init_mce)] + [float(x) for x in mce_trace_per_step]\n",
        "        if len(trace) != self.num_steps:\n",
        "            raise ValueError(\n",
        "                f\"MCE trace length mismatch for image {self.image_id}: \"\n",
        "                f\"got {len(trace)}, expected {self.num_steps} \"\n",
        "                f\"(= 1 init + {len(self.step_labels)-1} steps)\"\n",
        "            )\n",
        "        self._per_run_mce_traces.append(trace)\n",
        "        self._per_run_final_psnr.append(float(final_psnr))\n",
        "        self._per_run_final_mce.append(float(trace[-1]))\n",
        "\n",
        "    def to_dataframes(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          tidy_df: long table with (image, run, step_idx, step_label, mce)\n",
        "          per_image_summary_df: one row with per-step averages and changes, plus psnr_avg\n",
        "        \"\"\"\n",
        "        n_runs = len(self._per_run_mce_traces)\n",
        "        # --- Tidy long table ---\n",
        "        tidy_rows = []\n",
        "        for r, trace in enumerate(self._per_run_mce_traces, start=1):\n",
        "            for k, (label, mce_val) in enumerate(zip(self.step_labels, trace)):\n",
        "                tidy_rows.append({\n",
        "                    \"image\": self.image_id,\n",
        "                    \"run\": r,\n",
        "                    \"step_idx\": k,\n",
        "                    \"step_label\": label,\n",
        "                    \"mce\": float(mce_val),\n",
        "                })\n",
        "        tidy_df = pd.DataFrame(tidy_rows)\n",
        "\n",
        "        # --- Per-image averages per step ---\n",
        "        traces = np.array(self._per_run_mce_traces, dtype=float)  # shape (n_runs, num_steps)\n",
        "        step_means = traces.mean(axis=0)                # avg MCE per step\n",
        "        change_from_init = step_means - step_means[0]   # Δ vs initial per step\n",
        "        # Δ vs previous (NaN at initial)\n",
        "        change_from_prev = np.empty_like(step_means)\n",
        "        change_from_prev[:] = np.nan\n",
        "        change_from_prev[1:] = step_means[1:] - step_means[:-1]\n",
        "\n",
        "        psnr_avg = float(np.mean(self._per_run_final_psnr)) if len(self._per_run_final_psnr) else np.nan\n",
        "\n",
        "        # Build a single-row wide summary with:\n",
        "        #   MCE_<label>, dInit_<label>, dPrev_<label>, and final_psnr_avg\n",
        "        summary = {\"image\": self.image_id, \"final_psnr_avg\": psnr_avg}\n",
        "        for lbl, m, dI, dP in zip(self.step_labels, step_means, change_from_init, change_from_prev):\n",
        "            summary[f\"MCE_{lbl}\"]   = float(m)\n",
        "            summary[f\"dInit_{lbl}\"] = float(dI)\n",
        "            summary[f\"dPrev_{lbl}\"] = float(dP) if not math.isnan(dP) else np.nan\n",
        "\n",
        "        per_image_summary_df = pd.DataFrame([summary])\n",
        "        return tidy_df, per_image_summary_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7017b7c",
      "metadata": {
        "id": "f7017b7c"
      },
      "outputs": [],
      "source": [
        "# --- Config (as you already have) ---\n",
        "out = []\n",
        "n_step = 20\n",
        "scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "step_size = 1000 // n_step\n",
        "dtype = torch.float32\n",
        "\n",
        "# Where to save the outputs:\n",
        "export_dir = \"./dm_results_exports\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "# Collect all images’ tidy/wide in memory to write one combined CSV per type\n",
        "all_tidy = []\n",
        "all_summary = []\n",
        "\n",
        "for j in range(11, 12):\n",
        "    filename = f\"{j:05d}.png\"   # 00011 ... 00020\n",
        "    filepath = os.path.join(\"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\", filename)\n",
        "\n",
        "    gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "    ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "    x = ref_numpy * 2 - 1\n",
        "    x = x.transpose(2, 0, 1)\n",
        "    ref_img = torch.tensor(x, dtype=dtype, device=device).unsqueeze(0)\n",
        "    ref_img.requires_grad = False\n",
        "\n",
        "    # Forward measurement model (Ax + n)\n",
        "    if measure_config['operator']['name'] == 'inpainting':\n",
        "        measurement_cond_fn = partial(cond_method.conditioning, mask=mask)\n",
        "        sample_fn = partial(sample_fn, measurement_cond_fn=measurement_cond_fn)\n",
        "        y = operator.forward(ref_img, mask=mask)\n",
        "        y_n = noiser(y)\n",
        "    else:\n",
        "        y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)\n",
        "\n",
        "    gt = (ref_img / 2 + 0.5)  # in [0,1] torch\n",
        "    gt_np = gt.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()  # (H,W,C) in [0,1]\n",
        "\n",
        "    gt = (ref_img/2+0.5)\n",
        "    # resize_transform = torchvision.transforms.Resize((256,256))\n",
        "\n",
        "    num_runs = 2\n",
        "    print(f\"Reconstructing Image {filename}...\")\n",
        "\n",
        "    # Create per-image recorder\n",
        "    rec = DMRunRecorder(image_id=f\"{j:05d}\", scheduler=scheduler)\n",
        "\n",
        "    for run_iter in range(num_runs):\n",
        "        # fresh init\n",
        "        input =torch.randn((1, 3, 256, 256), device=device, dtype=dtype).clone().detach().requires_grad_(True)\n",
        "        noise = torch.randn(input.shape)*((1-scheduler.alphas_cumprod[-1])**0.5)\n",
        "        input = torch.tensor(input)*((scheduler.alphas_cumprod[-1])**0.5) + noise.to(device)\n",
        "\n",
        "        # Initial MCE (using the *current sample*; for pure theory you might prefer pred_original_sample @ init)\n",
        "        init_mce = compute_mce(input, y_n.abs(), target_shape=y_n.shape)\n",
        "\n",
        "        # Will store MCE at each diffusion step\n",
        "        mce_trace = []\n",
        "\n",
        "        # Diffusion sweep\n",
        "        pred_original_sample = None  # keep last\n",
        "        for i, t in enumerate(scheduler.timesteps):\n",
        "            prev_timestep = t - step_size\n",
        "            alpha_prod_t = scheduler.alphas_cumprod[t]\n",
        "            alpha_prod_t_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "            beta_prod_t = 1 - alpha_prod_t\n",
        "            sqrt_one_minus_alpha_cumprod = beta_prod_t ** 0.5\n",
        "\n",
        "            # Optimize current latent toward measurement consistency (your routine)\n",
        "            input, pred_original_sample, noise_pred = optimize_input(\n",
        "                input.clone(),\n",
        "                sqrt_one_minus_alpha_cumprod,\n",
        "                alpha_prod_t ** 0.5,\n",
        "                t,\n",
        "                num_steps=20,\n",
        "                learning_rate=0.075\n",
        "            )\n",
        "\n",
        "\n",
        "            # Compute MCE on denoised image proxy\n",
        "            phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "            mce_val = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "            mce_trace.append(float(mce_val))\n",
        "\n",
        "            # Prepare next step x_{t-1}\n",
        "            input = pred_original_sample * (alpha_prod_t_prev ** 0.5) + (1 - alpha_prod_t_prev) ** 0.5 * torch.randn_like(input)\n",
        "\n",
        "        # Final recon for PSNR (use last pred_original_sample)\n",
        "        phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "        recon_np = phase_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "        final_psnr = float(compute_psnr(recon_np, gt_np))\n",
        "\n",
        "        # Record the run (this stores [init] + per-step MCE trace under the hood)\n",
        "        rec.record_run(init_mce=float(init_mce), mce_trace_per_step=mce_trace, final_psnr=final_psnr)\n",
        "\n",
        "    # After all runs for this image: convert to DataFrames\n",
        "    tidy_df, summary_df = rec.to_dataframes()\n",
        "\n",
        "    # Save per-image (optional)\n",
        "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tidy_path    = os.path.join(export_dir, f\"{j:05d}_runs_tidy_{ts}.csv\")\n",
        "    summary_path = os.path.join(export_dir, f\"{j:05d}_summary_{ts}.csv\")\n",
        "    tidy_df.to_csv(tidy_path, index=False)\n",
        "    summary_df.to_csv(summary_path, index=False)\n",
        "\n",
        "    # Accumulate for global combined files\n",
        "    all_tidy.append(tidy_df)\n",
        "    all_summary.append(summary_df)\n",
        "\n",
        "# Write global combined CSVs (all images)\n",
        "tidy_all = pd.concat(all_tidy, ignore_index=True)\n",
        "summary_all = pd.concat(all_summary, ignore_index=True)\n",
        "tidy_all_path = os.path.join(export_dir, f\"ALL_images_runs_tidy_{n_step}.csv\")\n",
        "summary_all_path = os.path.join(export_dir, f\"ALL_images_summary_wide_{n_step}.csv\")\n",
        "tidy_all.to_csv(tidy_all_path, index=False)\n",
        "summary_all.to_csv(summary_all_path, index=False)\n",
        "\n",
        "# Optional: write one consolidated Excel with two sheets\n",
        "# xlsx_path = os.path.join(export_dir, \"ALL_images_results.xlsx\")\n",
        "# with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as writer:\n",
        "#    tidy_all.to_excel(writer, sheet_name=\"runs_tidy\", index=False)\n",
        "#    summary_all.to_excel(writer, sheet_name=\"summary_wide\", index=False)\n",
        "\n",
        "print(\"Saved:\", tidy_all_path, summary_all_path, xlsx_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1176d30c",
      "metadata": {
        "id": "1176d30c"
      },
      "outputs": [],
      "source": [
        "# --- Long-format exporters (place this right after you have tidy_all & summary_all) ---\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 0) Make sure your export dir exists\n",
        "export_dir = \"./dm_results_exports\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "# 1) Save per-run tidy exactly as-is (already long)\n",
        "tidy_all_path = os.path.join(export_dir, f\"ALL_images_runs_tidy_{n_step}.csv\")\n",
        "tidy_all.to_csv(tidy_all_path, index=False)\n",
        "\n",
        "# 2) Convert per-image \"wide\" summary to long, with clean step ordering\n",
        "def _step_sort_key(lbl: str):\n",
        "    # order: initial first, then t<...> descending (t1000, t950, ..., t0)\n",
        "    if lbl == \"initial\":\n",
        "        return (0, 0)  # smallest\n",
        "    m = re.fullmatch(r\"t(\\d+)\", lbl)\n",
        "    if m:\n",
        "        return (1, -int(m.group(1)))  # descending by numeric\n",
        "    # put anything unknown last, stable order\n",
        "    return (2, lbl)\n",
        "\n",
        "def summary_wide_to_long(summary_wide_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Input columns include:\n",
        "      - image\n",
        "      - final_psnr_avg\n",
        "      - MCE_<label>, dInit_<label>, dPrev_<label> for labels in {'initial','tXXXX',...}\n",
        "    Output long DF (one row per image, per step label):\n",
        "      image, step_idx, step_label, avg_mce, dInit, dPrev\n",
        "    Plus an extra row with step_label='final_psnr' containing final_psnr_avg.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for _, row in summary_wide_df.iterrows():\n",
        "        img = row[\"image\"]\n",
        "        # discover labels present by scanning MCE_* keys\n",
        "        labels = [k.replace(\"MCE_\", \"\") for k in row.index if str(k).startswith(\"MCE_\")]\n",
        "        labels = sorted(labels, key=_step_sort_key)\n",
        "\n",
        "        for k, lbl in enumerate(labels):\n",
        "            mce   = float(row[f\"MCE_{lbl}\"])\n",
        "            dInit = float(row.get(f\"dInit_{lbl}\", np.nan))\n",
        "            dPrev = float(row.get(f\"dPrev_{lbl}\", np.nan))\n",
        "            rows.append({\n",
        "                \"image\": img,\n",
        "                \"step_idx\": k,\n",
        "                \"step_label\": lbl,\n",
        "                \"avg_mce\": mce,\n",
        "                \"dInit\": dInit,\n",
        "                \"dPrev\": dPrev,\n",
        "            })\n",
        "\n",
        "        # append PSNR as one special row (no MCE/diffs there)\n",
        "        rows.append({\n",
        "            \"image\": img,\n",
        "            \"step_idx\": len(labels),          # after the last step\n",
        "            \"step_label\": \"final_psnr\",\n",
        "            \"avg_mce\": np.nan,\n",
        "            \"dInit\": np.nan,\n",
        "            \"dPrev\": np.nan,\n",
        "            \"final_psnr_avg\": float(row[\"final_psnr_avg\"]),\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# 5 decimal places everywhere; no scientific notation\n",
        "step_averages_long = summary_wide_to_long(summary_all)\n",
        "step_averages_long_path = os.path.join(export_dir, f\"ALL_images_step_averages_long_{n_step}.csv\")\n",
        "step_averages_long.to_csv(step_averages_long_path, index=False)\n",
        "\n",
        "\n",
        "# 3) (Optional) Ultra-tidy molten table: one value per row (handy for seaborn/plotnine)\n",
        "#    Produces rows like: (image, step_idx, step_label, metric, value)\n",
        "def melt_step_averages_long(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    part_mce = df.loc[df[\"step_label\"] != \"final_psnr\",\n",
        "                      [\"image\",\"step_idx\",\"step_label\",\"avg_mce\",\"dInit\",\"dPrev\"]].copy()\n",
        "    melted_mce = part_mce.melt(id_vars=[\"image\",\"step_idx\",\"step_label\"],\n",
        "                               value_vars=[\"avg_mce\",\"dInit\",\"dPrev\"],\n",
        "                               var_name=\"metric\",\n",
        "                               value_name=\"value\")\n",
        "    part_psnr = df.loc[df[\"step_label\"] == \"final_psnr\",\n",
        "                       [\"image\",\"step_idx\",\"step_label\",\"final_psnr_avg\"]].copy()\n",
        "    part_psnr = part_psnr.rename(columns={\"final_psnr_avg\":\"value\"})\n",
        "    part_psnr[\"metric\"] = \"final_psnr_avg\"\n",
        "    part_psnr = part_psnr[[\"image\",\"step_idx\",\"step_label\",\"metric\",\"value\"]]\n",
        "    return pd.concat([melted_mce, part_psnr], ignore_index=True)\n",
        "\n",
        "metrics_long = melt_step_averages_long(step_averages_long)\n",
        "metrics_long_path = os.path.join(export_dir, \"ALL_images_metrics_long.csv\")\n",
        "metrics_long.to_csv(metrics_long_path, index=False)\n",
        "\n",
        "tidy_all.to_csv(tidy_all_path, index=False, float_format=\"%.5f\")\n",
        "step_averages_long.to_csv(step_averages_long_path, index=False, float_format=\"%.5f\")\n",
        "metrics_long.to_csv(metrics_long_path, index=False, float_format=\"%.5f\")\n",
        "\n",
        "print(\"Saved long-format files:\")\n",
        "print(\" • Per-run tidy:\", tidy_all_path)\n",
        "print(\" • Per-image step averages (long):\", step_averages_long_path)\n",
        "print(\" • (Optional) Ultra-tidy metric/value table:\", metrics_long_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ce96955",
      "metadata": {
        "id": "9ce96955"
      },
      "source": [
        "No Pandas -- Try This"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c15465f7",
      "metadata": {
        "id": "c15465f7"
      },
      "outputs": [],
      "source": [
        "# ======== NO-PANDAS RECORDER + EXPORTS ========\n",
        "import os, time, json, math, csv\n",
        "import numpy as np\n",
        "\n",
        "# ----- formatting helpers -----\n",
        "# --- helper: pretty-print an MCE trace for one run ---\n",
        "def print_mce_trace(run_idx: int, mces, timesteps):\n",
        "    \"\"\"\n",
        "    mces: list[Tensor/float] with [init_mce, mce_at_t_0, mce_at_t_1, ...]\n",
        "    timesteps: iterable of scheduler timesteps aligned with mces[1:]\n",
        "    \"\"\"\n",
        "    # ensure plain floats for printing\n",
        "    mces_f = [float(m) for m in mces]\n",
        "\n",
        "    print(f\"\\nMCE trace for run {run_idx + 1}:\")\n",
        "    print(f\"  init: {mces_f[0]:.4f}\")\n",
        "    for k, (t, m) in enumerate(zip(timesteps, mces_f[1:]), 1):\n",
        "        # right-aligned columns: step, t, value\n",
        "        print(f\"  step {k:3d} (t={int(t):5d}): {m:8.4f}\")\n",
        "    print()  # blank line for spacing\n",
        "\n",
        "def is_nan(x):\n",
        "    try:\n",
        "        return np.isnan(x)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def fmt5(x):\n",
        "    \"\"\"Format floats to 5 decimals; return '' for NaN/None.\"\"\"\n",
        "    if x is None or is_nan(x):\n",
        "        return \"\"\n",
        "    return f\"{float(x):.5f}\"\n",
        "\n",
        "def fmt2(x):\n",
        "    if x is None or is_nan(x):\n",
        "        return \"\"\n",
        "    return f\"{float(x):.2f}\"\n",
        "\n",
        "# ----- step label helpers -----\n",
        "def _make_step_labels(scheduler, include_init=True):\n",
        "    labels = []\n",
        "    if include_init:\n",
        "        labels.append(\"initial\")\n",
        "    for t in list(scheduler.timesteps):  # typically descending\n",
        "        labels.append(f\"t{int(t)}\")\n",
        "    return labels\n",
        "\n",
        "def _step_sort_key(lbl: str):\n",
        "    # order: initial first, then t<...> descending (t1000, t950, ..., t0)\n",
        "    if lbl == \"initial\":\n",
        "        return (0, 0)\n",
        "    if lbl.startswith(\"t\") and lbl[1:].isdigit():\n",
        "        return (1, -int(lbl[1:]))\n",
        "    return (2, lbl)\n",
        "\n",
        "# ----- recorder without pandas -----\n",
        "class DMRunRecorderNP:\n",
        "    \"\"\"\n",
        "    Accumulates per-run MCE traces and PSNRs for one image,\n",
        "    then produces tidy rows and a single wide summary dict.\n",
        "    \"\"\"\n",
        "    def __init__(self, image_id, scheduler):\n",
        "        self.image_id = image_id\n",
        "        self.scheduler = scheduler\n",
        "        self.step_labels = _make_step_labels(scheduler, include_init=True)\n",
        "        self.num_steps = len(self.step_labels)\n",
        "        self._per_run_mce_traces = []  # list[list[float]] length = num_steps\n",
        "        self._per_run_final_psnr = []  # list[float]\n",
        "\n",
        "    def record_run(self, init_mce, mce_trace_per_step, final_psnr):\n",
        "        assert isinstance(mce_trace_per_step, (list, tuple)), \"mce_trace_per_step must be list/tuple\"\n",
        "        trace = [float(init_mce)] + [float(x) for x in mce_trace_per_step]\n",
        "        if len(trace) != self.num_steps:\n",
        "            raise ValueError(\n",
        "                f\"MCE trace length mismatch for image {self.image_id}: \"\n",
        "                f\"got {len(trace)}, expected {self.num_steps} \"\n",
        "                f\"(= 1 init + {len(self.step_labels)-1} steps)\"\n",
        "            )\n",
        "        self._per_run_mce_traces.append(trace)\n",
        "        self._per_run_final_psnr.append(float(final_psnr))\n",
        "\n",
        "    def to_records(self):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "          tidy_rows: list of dicts: {image, run, step_idx, step_label, mce}\n",
        "          summary_row: dict with keys:\n",
        "            - 'image', 'final_psnr_avg'\n",
        "            - 'MCE_<label>', 'dInit_<label>', 'dPrev_<label>' for each step label\n",
        "        \"\"\"\n",
        "        # --- tidy rows (long per-run) ---\n",
        "        tidy_rows = []\n",
        "        for r, trace in enumerate(self._per_run_mce_traces, start=1):\n",
        "            for k, (label, mce_val) in enumerate(zip(self.step_labels, trace)):\n",
        "                tidy_rows.append({\n",
        "                    \"image\": self.image_id,\n",
        "                    \"run\": r,\n",
        "                    \"step_idx\": k,\n",
        "                    \"step_label\": label,\n",
        "                    \"mce\": float(mce_val),\n",
        "                })\n",
        "\n",
        "        # --- per-image averages per step ---\n",
        "        traces = np.array(self._per_run_mce_traces, dtype=float)  # (n_runs, num_steps)\n",
        "        step_means = traces.mean(axis=0) if traces.size > 0 else np.full(self.num_steps, np.nan)\n",
        "        dInit = step_means - step_means[0] if traces.size > 0 else np.full(self.num_steps, np.nan)\n",
        "        dPrev = np.full(self.num_steps, np.nan)\n",
        "        if traces.size > 0:\n",
        "            dPrev[1:] = step_means[1:] - step_means[:-1]\n",
        "\n",
        "        psnr_avg = float(np.mean(self._per_run_final_psnr)) if len(self._per_run_final_psnr) else np.nan\n",
        "\n",
        "        summary_row = {\"image\": self.image_id, \"final_psnr_avg\": psnr_avg}\n",
        "        for lbl, m, di, dp in zip(self.step_labels, step_means, dInit, dPrev):\n",
        "            summary_row[f\"MCE_{lbl}\"]   = float(m)\n",
        "            summary_row[f\"dInit_{lbl}\"] = float(di)\n",
        "            summary_row[f\"dPrev_{lbl}\"] = float(dp)\n",
        "        return tidy_rows, summary_row\n",
        "\n",
        "# ----- CSV writing helpers (no pandas) -----\n",
        "def write_runs_tidy_csv(path, rows):\n",
        "    # rows: list of dicts with keys [\"image\",\"run\",\"step_idx\",\"step_label\",\"mce\"]\n",
        "    header = [\"image\",\"run\",\"step_idx\",\"step_label\",\"mce\"]\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(header)\n",
        "        for r in rows:\n",
        "            w.writerow([\n",
        "                r[\"image\"], int(r[\"run\"]), int(r[\"step_idx\"]), r[\"step_label\"], fmt5(r[\"mce\"])\n",
        "            ])\n",
        "\n",
        "def build_summary_wide_header(step_labels):\n",
        "    header = [\"image\", \"final_psnr_avg\"]\n",
        "    for lbl in step_labels:\n",
        "        header += [f\"MCE_{lbl}\", f\"dInit_{lbl}\", f\"dPrev_{lbl}\"]\n",
        "    return header\n",
        "\n",
        "def write_summary_wide_csv(path, rows, step_labels):\n",
        "    # rows: list of summary_row dicts from recorder\n",
        "    header = build_summary_wide_header(step_labels)\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(header)\n",
        "        for r in rows:\n",
        "            row_out = [r[\"image\"], fmt5(r.get(\"final_psnr_avg\", np.nan))]\n",
        "            for lbl in step_labels:\n",
        "                row_out.append(fmt5(r.get(f\"MCE_{lbl}\", np.nan)))\n",
        "                row_out.append(fmt5(r.get(f\"dInit_{lbl}\", np.nan)))\n",
        "                row_out.append(fmt5(r.get(f\"dPrev_{lbl}\", np.nan)))\n",
        "            w.writerow(row_out)\n",
        "\n",
        "def summary_wide_to_step_averages_long(summary_rows, step_labels):\n",
        "    \"\"\"\n",
        "    summary_rows: list of summary_row dicts\n",
        "    Returns list of dict rows:\n",
        "      - for MCE steps: {image, step_idx, step_label, avg_mce, dInit, dPrev}\n",
        "      - for PSNR:      {image, step_idx, step_label='final_psnr', final_psnr_avg}\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    # ensure sorted step order\n",
        "    ordered = sorted(step_labels, key=_step_sort_key)\n",
        "    for r in summary_rows:\n",
        "        img = r[\"image\"]\n",
        "        for k, lbl in enumerate(ordered):\n",
        "            out.append({\n",
        "                \"image\": img,\n",
        "                \"step_idx\": k,\n",
        "                \"step_label\": lbl,\n",
        "                \"avg_mce\": r.get(f\"MCE_{lbl}\", np.nan),\n",
        "                \"dInit\":   r.get(f\"dInit_{lbl}\", np.nan),\n",
        "                \"dPrev\":   r.get(f\"dPrev_{lbl}\", np.nan),\n",
        "            })\n",
        "        out.append({\n",
        "            \"image\": img,\n",
        "            \"step_idx\": len(ordered),\n",
        "            \"step_label\": \"final_psnr\",\n",
        "            \"final_psnr_avg\": r.get(\"final_psnr_avg\", np.nan),\n",
        "        })\n",
        "    return out\n",
        "\n",
        "def write_step_averages_long_csv(path, rows):\n",
        "    # rows: from summary_wide_to_step_averages_long\n",
        "    # Columns: image, step_idx, step_label, avg_mce, dInit, dPrev, (optional) final_psnr_avg\n",
        "    header = [\"image\",\"step_idx\",\"step_label\",\"avg_mce\",\"dInit\",\"dPrev\",\"final_psnr_avg\"]\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(header)\n",
        "        for r in rows:\n",
        "            if r[\"step_label\"] == \"final_psnr\":\n",
        "                w.writerow([r[\"image\"], int(r[\"step_idx\"]), \"final_psnr\", \"\", \"\", \"\", fmt5(r[\"final_psnr_avg\"])])\n",
        "            else:\n",
        "                w.writerow([\n",
        "                    r[\"image\"], int(r[\"step_idx\"]), r[\"step_label\"],\n",
        "                    fmt5(r[\"avg_mce\"]), fmt5(r[\"dInit\"]), fmt5(r[\"dPrev\"]), \"\"\n",
        "                ])\n",
        "\n",
        "def melt_metrics_long(step_avg_long_rows):\n",
        "    \"\"\"\n",
        "    Input: rows from summary_wide_to_step_averages_long\n",
        "    Output: list of dicts with columns: image, step_idx, step_label, metric, value\n",
        "    Where metric ∈ {'avg_mce','dInit','dPrev'} for MCE steps, or 'final_psnr_avg' for PSNR row.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for r in step_avg_long_rows:\n",
        "        if r[\"step_label\"] == \"final_psnr\":\n",
        "            out.append({\n",
        "                \"image\": r[\"image\"], \"step_idx\": r[\"step_idx\"], \"step_label\": \"final_psnr\",\n",
        "                \"metric\": \"final_psnr_avg\", \"value\": r.get(\"final_psnr_avg\", np.nan)\n",
        "            })\n",
        "        else:\n",
        "            for mkey in [\"avg_mce\",\"dInit\",\"dPrev\"]:\n",
        "                out.append({\n",
        "                    \"image\": r[\"image\"], \"step_idx\": r[\"step_idx\"], \"step_label\": r[\"step_label\"],\n",
        "                    \"metric\": mkey, \"value\": r.get(mkey, np.nan)\n",
        "                })\n",
        "    return out\n",
        "\n",
        "def write_metrics_long_csv(path, rows):\n",
        "    header = [\"image\",\"step_idx\",\"step_label\",\"metric\",\"value\"]\n",
        "    with open(path, \"w\", newline=\"\") as f:\n",
        "        w = csv.writer(f)\n",
        "        w.writerow(header)\n",
        "        for r in rows:\n",
        "            w.writerow([r[\"image\"], int(r[\"step_idx\"]), r[\"step_label\"], r[\"metric\"], fmt5(r[\"value\"])])\n",
        "\n",
        "# ======== INTEGRATE WITH YOUR MAIN LOOP (replace pandas bits) ========\n",
        "\n",
        "# --- Config (as you already have) ---\n",
        "out = []\n",
        "n_step = 20\n",
        "scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "step_size = 1000 // n_step\n",
        "dtype = torch.float32\n",
        "\n",
        "# Save dir\n",
        "export_dir = \"./dm_results_exports\"\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "all_tidy_rows = []     # accumulate all images' tidy rows\n",
        "all_summary_rows = []  # accumulate all images' summary rows\n",
        "global_step_labels = _make_step_labels(scheduler, include_init=True)\n",
        "\n",
        "for j in range(19, 20):  # adjust range as needed\n",
        "    filename = f\"{j:05d}.png\"\n",
        "    filepath = os.path.join(\"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\", filename)\n",
        "\n",
        "    gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "    ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "    x = ref_numpy * 2 - 1\n",
        "    x = x.transpose(2, 0, 1)\n",
        "    ref_img = torch.tensor(x, dtype=dtype, device=device).unsqueeze(0)\n",
        "    ref_img.requires_grad = False\n",
        "\n",
        "    # Forward measurement model (Ax + n)\n",
        "    if measure_config['operator']['name'] == 'inpainting':\n",
        "        measurement_cond_fn = partial(cond_method.conditioning, mask=mask)\n",
        "        sample_fn = partial(sample_fn, measurement_cond_fn=measurement_cond_fn)\n",
        "        y = operator.forward(ref_img, mask=mask)\n",
        "        y_n = noiser(y)\n",
        "    else:\n",
        "        y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)\n",
        "\n",
        "    gt = (ref_img / 2 + 0.5)\n",
        "    gt_np = gt.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "    num_runs = 10\n",
        "    print(f\"Reconstructing Image {filename}...\")\n",
        "\n",
        "    rec = DMRunRecorderNP(image_id=f\"{j:05d}\", scheduler=scheduler)\n",
        "\n",
        "    for run_iter in range(num_runs):\n",
        "        # fresh init\n",
        "        # input = torch.randn((1, 3, 256, 256), device=device, dtype=dtype).clone().detach().requires_grad_(True)\n",
        "        # noise = torch.randn_like(input) * ((1 - scheduler.alphas_cumprod[-1]) ** 0.5)\n",
        "        # input = input * (scheduler.alphas_cumprod[-1] ** 0.5) + noise  # avoid torch.tensor(input)\n",
        "\n",
        "        input =torch.randn((1, 3, 256, 256), device=device, dtype=dtype).clone().detach().requires_grad_(True)\n",
        "        noise = torch.randn(input.shape)*((1-scheduler.alphas_cumprod[-1])**0.5)\n",
        "        input = torch.tensor(input)*((scheduler.alphas_cumprod[-1])**0.5) + noise.to(device)\n",
        "\n",
        "\n",
        "        # Initial MCE\n",
        "        init_mce = compute_mce(input, y_n.abs(), target_shape=y_n.shape)\n",
        "\n",
        "        mce_trace = []\n",
        "        pred_original_sample = None\n",
        "\n",
        "        for i, t in enumerate(scheduler.timesteps):\n",
        "            prev_timestep = t - step_size\n",
        "            alpha_prod_t = scheduler.alphas_cumprod[t]\n",
        "            alpha_prod_t_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "            beta_prod_t = 1 - alpha_prod_t\n",
        "            sqrt_one_minus_alpha_cumprod = beta_prod_t ** 0.5\n",
        "\n",
        "            # Your inner optimizer (ensure it builds a fresh graph per iter, as discussed earlier)\n",
        "            input, pred_original_sample, noise_pred = optimize_input(\n",
        "                input.clone(),\n",
        "                sqrt_one_minus_alpha_cumprod,\n",
        "                alpha_prod_t ** 0.5,\n",
        "                t,\n",
        "                num_steps=20,\n",
        "                learning_rate=0.075\n",
        "            )\n",
        "\n",
        "            phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "            mce_val = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "            mce_trace.append(float(mce_val))\n",
        "\n",
        "            input = pred_original_sample * (alpha_prod_t_prev ** 0.5) + (1 - alpha_prod_t_prev) ** 0.5 * torch.randn_like(input)\n",
        "\n",
        "        # Final PSNR\n",
        "        phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "        recon_np = phase_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "        final_psnr = float(compute_psnr(recon_np, gt_np))\n",
        "\n",
        "        rec.record_run(init_mce=float(init_mce), mce_trace_per_step=mce_trace, final_psnr=final_psnr)\n",
        "\n",
        "    # Convert to tidy rows + per-image summary row (no pandas)\n",
        "    tidy_rows, summary_row = rec.to_records()\n",
        "    # Write per-image (optional)\n",
        "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    per_image_tidy_path = os.path.join(export_dir, f\"{j:05d}_runs_tidy_{ts}_{j}.csv\")\n",
        "    per_image_summary_path = os.path.join(export_dir, f\"{j:05d}_summary_{ts}_{j}.csv\")\n",
        "    write_runs_tidy_csv(per_image_tidy_path, tidy_rows)\n",
        "    write_summary_wide_csv(per_image_summary_path, [summary_row], rec.step_labels)\n",
        "\n",
        "    # Accumulate\n",
        "    all_tidy_rows.extend(tidy_rows)\n",
        "    all_summary_rows.append(summary_row)\n",
        "\n",
        "# ---- Write combined CSVs (ALL images) ----\n",
        "tidy_all_path = os.path.join(export_dir, f\"ALL_images_runs_tidy_{n_step}_{j}.csv\")\n",
        "summary_wide_all_path = os.path.join(export_dir, f\"ALL_images_summary_wide_{n_step}_{j}.csv\")\n",
        "write_runs_tidy_csv(tidy_all_path, all_tidy_rows)\n",
        "write_summary_wide_csv(summary_wide_all_path, all_summary_rows, global_step_labels)\n",
        "\n",
        "# ---- Long per-image step averages (avg_mce, dInit, dPrev) + PSNR row ----\n",
        "step_averages_long_rows = summary_wide_to_step_averages_long(all_summary_rows, global_step_labels)\n",
        "step_averages_long_path = os.path.join(export_dir, f\"ALL_images_step_averages_long_{n_step}_{j}.csv\")\n",
        "write_step_averages_long_csv(step_averages_long_path, step_averages_long_rows)\n",
        "\n",
        "# ---- Ultra-tidy metric/value table (optional) ----\n",
        "metrics_long_rows = melt_metrics_long(step_averages_long_rows)\n",
        "metrics_long_path = os.path.join(export_dir, f\"ALL_images_metrics_long_{n_step}_{j}.csv\")\n",
        "write_metrics_long_csv(metrics_long_path, metrics_long_rows)\n",
        "\n",
        "print(\"Saved:\")\n",
        "print(\" • Per-run tidy:\", tidy_all_path)\n",
        "print(\" • Per-image summary wide:\", summary_wide_all_path)\n",
        "print(\" • Per-image step averages (long):\", step_averages_long_path)\n",
        "print(\" • Ultra-tidy metric/value table:\", metrics_long_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b08a09d",
      "metadata": {
        "id": "9b08a09d"
      },
      "source": [
        "Old one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15d35617",
      "metadata": {
        "id": "15d35617"
      },
      "outputs": [],
      "source": [
        "## Make one file for multi run testing\n",
        "\n",
        "out = []\n",
        "n_step = 20\n",
        "scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "step_size = 1000//n_step\n",
        "dtype = torch.float32\n",
        "\n",
        "# Loop through images 00011, 00012, …, 00019 etc... i\n",
        "\n",
        "for j in range(11, 12):\n",
        "    filename = f\"{j:05d}.png\"            # 00011, 00012, …, 00019 etc... i\n",
        "    filepath = os.path.join(\"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\", filename)\n",
        "    gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "    #shutil.copy(gt_img_path, os.path.join(logdir, 'gt.png'))\n",
        "    ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "    x = ref_numpy * 2 - 1\n",
        "    x = x.transpose(2, 0, 1)\n",
        "    ref_img = torch.Tensor(x).to(dtype).to(device).unsqueeze(0)\n",
        "    ref_img.requires_grad = False\n",
        "    #ref_img = ref_img.to(device)\n",
        "    if measure_config['operator'] ['name'] == 'inpainting':\n",
        "        mask = mask\n",
        "        measurement_cond_fn = partial(cond_method.conditioning, mask=mask)\n",
        "        sample_fn = partial(sample_fn, measurement_cond_fn=measurement_cond_fn)\n",
        "\n",
        "        # Forward measurement model (Ax + n)\n",
        "        y = operator.forward(ref_img, mask=mask)\n",
        "        y_n = noiser(y)\n",
        "\n",
        "    else:\n",
        "        # Forward measurement model (Ax + n)\n",
        "        y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)\n",
        "        #y_n = torch.clamp(y_n,-1,1)\n",
        "    #y_n.requires_grad = False\n",
        "\n",
        "    gt = (ref_img/2+0.5)\n",
        "    resize_transform = torchvision.transforms.Resize((256,256))\n",
        "\n",
        "    # Multi-Run Testing\n",
        "\n",
        "    num_runs = 2\n",
        "    run_results = []\n",
        "    mce_results = []\n",
        "    per_image_results = []        # optional: collect per-run records for this image\n",
        "\n",
        "    print(f\"Reconstructing Image {filename}...\")\n",
        "    for run_iter in range(num_runs):\n",
        "        # print('Run Number:', run_iter + 1)\n",
        "\n",
        "        # Clear output visualization in case didn't rerun\n",
        "        out_visual = []\n",
        "        measurement_errors = []\n",
        "\n",
        "        input =torch.randn((1, 3, 256, 256), device=device, dtype=dtype).clone().detach().requires_grad_(True)\n",
        "        noise = torch.randn(input.shape)*((1-scheduler.alphas_cumprod[-1])**0.5)\n",
        "        input = torch.tensor(input)*((scheduler.alphas_cumprod[-1])**0.5) + noise.to(device)\n",
        "\n",
        "        # Print Initial MCE\n",
        "        init_mce = compute_mce(input, y_n.abs(), target_shape=y_n.shape) # In practice we don't have access to GT during DMs, otherwise we just know GT\n",
        "        # print(f\"Initial MCE:, {init_mce: .4f}\")\n",
        "\n",
        "        for i, t in enumerate(scheduler.timesteps):\n",
        "            prev_timestep = t - step_size\n",
        "\n",
        "            alpha_prod_t = scheduler.alphas_cumprod[t]\n",
        "            alpha_prod_t_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "\n",
        "            beta_prod_t = 1 - alpha_prod_t\n",
        "            sqrt_one_minus_alpha_cumprod = beta_prod_t**0.5\n",
        "\n",
        "\n",
        "            #for k in range(1):\n",
        "            input, pred_original_sample, noise_pred= optimize_input(input.clone(), sqrt_one_minus_alpha_cumprod, alpha_prod_t**0.5, t, num_steps=20, learning_rate=0.075)\n",
        "            #    input= pred_original_sample * alpha_prod_t**0.5+(1-alpha_prod_t)**0.5*torch.randn(input.size()).to(device)\n",
        "\n",
        "            phase_image = (pred_original_sample / 2 + 0.5).clamp(0, 1)\n",
        "\n",
        "            # Compute measurement error with correct shape\n",
        "            mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "            measurement_errors.append(mce)\n",
        "\n",
        "            input = pred_original_sample * alpha_prod_t_prev**0.5+(1-alpha_prod_t_prev)**0.5*torch.randn(input.size()).to(device)\n",
        "\n",
        "            # print(f\"Time: {t}, , MCE: {mce:.4f}\")\n",
        "        input = (input/2+0.5).clamp(0, 1)\n",
        "        phase_image = (pred_original_sample/2+0.5).clamp(0, 1)\n",
        "        #input = (input + 1) / 2\n",
        "        phase_image = phase_image.squeeze(0).permute(1, 2, 0).detach().cpu().numpy()\n",
        "\n",
        "        run_results.append(phase_image)\n",
        "        mce_results.append(mce)\n",
        "\n",
        "        # (A) show the full MCE trace for this run in a neat block\n",
        "        print_mce_trace(run_iter, measurement_errors, scheduler.timesteps)\n",
        "\n",
        "        # (B) store results\n",
        "        run_results.append(phase_image)\n",
        "        mce_results.append(mce)  # final mce\n",
        "        per_image_results.append({\n",
        "            \"run\": run_iter + 1,\n",
        "            \"init_mce\": float(measurement_errors[0]),\n",
        "            \"final_mce\": float(measurement_errors[-1]),\n",
        "            \"mce_seq\": [float(v) for v in measurement_errors],  # full trace, including init\n",
        "        })\n",
        "\n",
        "        psnr_values = []\n",
        "    for i in range(num_runs):\n",
        "        #plt.imshow(run_results[i])\n",
        "        psnr_value = compute_psnr(np.array(run_results[i]), np.array(gt.cpu().detach().numpy()[0].transpose(1,2,0)))\n",
        "        psnr_values.append(psnr_value)\n",
        "        print(f\"After diffusion PSNR: {psnr_value} dB, MCE: {mce_results[i]: .4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b14072a",
      "metadata": {
        "id": "0b14072a"
      },
      "source": [
        "Reconstructing Image 00011.png...\n",
        "Run Number: 1\n",
        "/tmp/ipykernel_435532/1188489366.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
        "  input = torch.tensor(input)*((scheduler.alphas_cumprod[-1])**0.5) + noise.to(device)\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 28.100968456509925 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.270696040092986 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 11.455024601889816 dB, MCE:  0.0018\n",
        "After diffusion PSNR: 28.094056601340395 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.05229052845054 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 11.66003553083227 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 11.559687522342362 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 28.188196534392603 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.174921946261616 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.94670647299117 dB, MCE:  0.0015\n",
        "Reconstructing Image 00012.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 26.940155056594772 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.731576885850366 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.66404642307755 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.3286891149528 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.5034707883839 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.063347006811128 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.474818271877446 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.39552779143446 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.921228538103055 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.60586533247784 dB, MCE:  0.0015\n",
        "Reconstructing Image 00013.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 11.363108193156277 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 12.083036982990214 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 16.64904020110488 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 9.415043187755677 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 8.866917820733708 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 9.646573669323892 dB, MCE:  0.0018\n",
        "After diffusion PSNR: 20.269110522060153 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 8.729081822900417 dB, MCE:  0.0017\n",
        "After diffusion PSNR: 18.484052998158578 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 19.98795395736829 dB, MCE:  0.0016\n",
        "Reconstructing Image 00014.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 26.929716242264906 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.985969714366604 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.1693873825237 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.03242907426711 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.689538557373606 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.8395733024615 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 14.015525037617174 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 13.540458112686235 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 16.99490836422439 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 13.832507705817783 dB, MCE:  0.0016\n",
        "Reconstructing Image 00015.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 26.792820120253072 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.61752523171412 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.2816830756511 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.251475007559453 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 23.259608292515747 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 13.441754281690955 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 13.142495755413277 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 27.65922756139282 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 12.838730532741472 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 13.055441963791116 dB, MCE:  0.0016\n",
        "Reconstructing Image 00016.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 26.840034383038983 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.54649289923041 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.72653724075265 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.97125742699196 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.875255593484916 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.738405159443943 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.66921234342825 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.64957848482655 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.793223880376967 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.743999570460307 dB, MCE:  0.0015\n",
        "Reconstructing Image 00017.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 5.743272710826254 dB, MCE:  0.0018\n",
        "After diffusion PSNR: 28.798906000257546 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 6.072536987315037 dB, MCE:  0.0019\n",
        "After diffusion PSNR: 29.798010102832784 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 6.301213807972318 dB, MCE:  0.0019\n",
        "After diffusion PSNR: 29.87369556376093 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 6.1885579968220625 dB, MCE:  0.0019\n",
        "After diffusion PSNR: 5.940199347231086 dB, MCE:  0.0019\n",
        "After diffusion PSNR: 29.82425631453917 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 5.7959923188265705 dB, MCE:  0.0018\n",
        "Reconstructing Image 00018.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 24.562092359496937 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 23.784467321121895 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 25.996529788705093 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 24.70376010475503 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 21.411937894085934 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 24.390761619050757 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 24.411338219158726 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 23.61230814272552 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 15.035636875019094 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 26.055713929914674 dB, MCE:  0.0015\n",
        "Reconstructing Image 00019.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 28.03935703206749 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 8.808278893364239 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.248407550365442 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.072686061773776 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.225377001623496 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.993134702380956 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.604166988025618 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.248771017924174 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 9.373544984918373 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 28.186135946278633 dB, MCE:  0.0015\n",
        "Reconstructing Image 00020.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 27.631227521988883 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.329056739101052 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.61261121107919 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 14.489585813764085 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 27.75191148168183 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 17.78303706664373 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.783757170769945 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 15.750993342903797 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 27.142005428689583 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.940152676962033 dB, MCE:  0.0015\n",
        "Reconstructing Image 00021.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 27.633408238307045 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.86082722449575 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.493037341698866 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 25.957219039690766 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.46857552061432 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.08782169024601 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.702768071998 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.42008259849309 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.52073730703134 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.579953984064403 dB, MCE:  0.0015\n",
        "Reconstructing Image 00022.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 14.901366177258575 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 12.71349172138037 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 15.440604824776132 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 12.82896302130289 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 20.573017083742855 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 13.546121083431686 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 14.784194750770382 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 13.367328713870377 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 21.3134021394038 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 21.251997337143337 dB, MCE:  0.0015\n",
        "Reconstructing Image 00023.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 27.621637755416153 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.811321954763145 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.895848858924044 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.534319962033855 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.61300921728704 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.86293750311696 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.912073257060776 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.11110064973633 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 27.768674458919946 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 28.09685512216681 dB, MCE:  0.0015\n",
        "Reconstructing Image 00024.png...\n",
        "Run Number: 1\n",
        "Run Number: 2\n",
        "Run Number: 3\n",
        "Run Number: 4\n",
        "Run Number: 5\n",
        "Run Number: 6\n",
        "Run Number: 7\n",
        "Run Number: 8\n",
        "Run Number: 9\n",
        "Run Number: 10\n",
        "After diffusion PSNR: 17.48211655066524 dB, MCE:  0.0015\n",
        "After diffusion PSNR: 23.277887829279514 dB, MCE:  0.0014\n",
        "After diffusion PSNR: 23.51545800558304 dB, MCE:  0.0014\n",
        "After diffusion PSNR: 11.037143934600639 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 24.949964874942697 dB, MCE:  0.0014\n",
        "After diffusion PSNR: 13.931928073919355 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 21.19443340334766 dB, MCE:  0.0014\n",
        "After diffusion PSNR: 13.478402535412243 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 16.017040692484013 dB, MCE:  0.0016\n",
        "After diffusion PSNR: 14.512906661177137 dB, MCE:  0.0015"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a144c0c9",
      "metadata": {
        "id": "a144c0c9"
      },
      "source": [
        "## Trying: Enforce MCE Thresehold and Restrarting ##\n",
        "\n",
        "Note: Both dont work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f5157a",
      "metadata": {
        "id": "f0f5157a"
      },
      "outputs": [],
      "source": [
        "import os, torch, numpy as np, torchvision\n",
        "import torch.nn.functional as F\n",
        "from functools import partial\n",
        "from PIL import Image\n",
        "\n",
        "# --- assumes you already have: model, device, operator, noiser, measure_config, fft2c_new, ifft2c_new, DDIMScheduler ---\n",
        "\n",
        "# ========== helpers ==========\n",
        "\n",
        "def compute_mce(reconstructed_image, measured_magnitude, target_shape=None):\n",
        "    \"\"\"L2 error between Fourier magnitude of reconstruction (in [0,1]) and measured magnitude.\"\"\"\n",
        "    x_hat = reconstructed_image.clamp(0, 1)\n",
        "    if target_shape is not None:\n",
        "        _, _, H, W = x_hat.shape\n",
        "        target_H, target_W = target_shape[-2], target_shape[-1]\n",
        "        pad_h = (target_H - H) // 2\n",
        "        pad_w = (target_W - W) // 2\n",
        "        x_hat = F.pad(x_hat, (pad_w, pad_w, pad_h, pad_h))\n",
        "    if not torch.is_complex(x_hat):\n",
        "        x_hat = x_hat.type(torch.complex64)\n",
        "    fft_x_hat = torch.view_as_complex(fft2c_new(torch.view_as_real(x_hat)))\n",
        "    return (fft_x_hat.abs() - measured_magnitude).pow(2).mean().item()\n",
        "\n",
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse <= 0:\n",
        "        return float('inf')\n",
        "    return float(20 * np.log10(1.0 / (mse**0.5)))\n",
        "\n",
        "@torch.no_grad()\n",
        "def to_start_latent_from_x0(x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T, noise_scale=1.0):\n",
        "    \"\"\"\n",
        "    Given x0 in [-1,1], sample a start latent x_T = sqrt(alpha_bar_T)*x0 + sqrt(1-alpha_bar_T)*noise.\n",
        "    \"\"\"\n",
        "    eps = torch.randn_like(x0) * noise_scale\n",
        "    return sqrt_alpha_bar_T * x0 + sqrt_one_minus_alpha_bar_T * eps\n",
        "\n",
        "def optimize_input(\n",
        "    input_tensor, sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod, t, y_n,\n",
        "    num_steps=20, learning_rate=0.01\n",
        "):\n",
        "    \"\"\"\n",
        "    One inner optimization block producing (x_t_next, pred_x0, noise_pred).\n",
        "    Uses your model(x_t, t) -> eps_hat, and a magnitude data term vs y_n.\n",
        "    \"\"\"\n",
        "    x_t = input_tensor.clone().detach().requires_grad_(True)\n",
        "    opt = torch.optim.Adam([x_t], lr=learning_rate)\n",
        "    tt = (torch.ones(1, device=x_t.device, dtype=torch.long) * int(t))\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        opt.zero_grad()\n",
        "        noise_pred = model(x_t, tt)[:, :3]\n",
        "        pred_x0 = (x_t - sqrt_one_minus_alpha_cumprod * noise_pred) / sqrt_alpha_cumprod\n",
        "        pred_x0 = torch.clamp(pred_x0, -1, 1)\n",
        "\n",
        "        # pad and FFT magnitude for the data term\n",
        "        pad = int((2 / 8.0) * 256)\n",
        "        x = pred_x0 * 0.5 + 0.5\n",
        "        x = F.pad(x, (pad, pad, pad, pad))\n",
        "        if not torch.is_complex(x):\n",
        "            x = x.type(torch.complex64)\n",
        "        fft2_m = torch.view_as_complex(fft2c_new(torch.view_as_real(x)))\n",
        "        out_mag = fft2_m.abs()\n",
        "\n",
        "        data_loss = torch.norm(out_mag - y_n)**2\n",
        "        # small tether to keep x_t from drifting too wildly (optional)\n",
        "        reg_loss = 0.1 * torch.norm(input_tensor.detach() - x_t)**2\n",
        "        loss = data_loss + reg_loss\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    # recompute noise from the final pair (x_t, pred_x0)\n",
        "    noise = (x_t - sqrt_alpha_cumprod * pred_x0) / sqrt_one_minus_alpha_cumprod\n",
        "    return x_t.detach(), pred_x0.detach(), noise.detach()\n",
        "\n",
        "# ========== main loop with threshold-triggered restarts ==========\n",
        "\n",
        "def run_threshold_restart_experiment(\n",
        "    image_indices=range(11, 21),\n",
        "    num_runs=1,\n",
        "    n_step=20,\n",
        "    mce_threshold=0.00148,\n",
        "    max_restarts=5,\n",
        "    stop_on_hit=False,              # if True, stop as soon as threshold hit once\n",
        "    restart_noise_scale=0.5,       # 0 = deterministic reuse, 1 = full start noise\n",
        "    patience_restarts=None,         # e.g. 2: stop if no best-MCE improvement for 2 restarts\n",
        "    inner_opt_steps=20,\n",
        "    inner_lr=0.075,\n",
        "    seed=41\n",
        "):\n",
        "    # reproducibility\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "\n",
        "    scheduler = DDIMScheduler()\n",
        "    scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "    step_size = 1000 // n_step\n",
        "\n",
        "    dtype = torch.float32\n",
        "    results_table = []  # for stats / correlation\n",
        "\n",
        "    # Precompute start-time alphas\n",
        "    T = int(scheduler.timesteps[0].item())  # largest t (close to 1000)\n",
        "    alpha_bar_T = scheduler.alphas_cumprod[T].item()\n",
        "    sqrt_alpha_bar_T = alpha_bar_T**0.5\n",
        "    sqrt_one_minus_alpha_bar_T = (1.0 - alpha_bar_T)**0.5\n",
        "\n",
        "    for j in image_indices:\n",
        "        filename = f\"{j:05d}.png\"\n",
        "        filepath = os.path.join(\"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\", filename)\n",
        "        gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "        ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "        x = ref_numpy * 2 - 1\n",
        "        x = x.transpose(2, 0, 1)\n",
        "        ref_img = torch.tensor(x, dtype=dtype, device=device).unsqueeze(0)\n",
        "        gt = (ref_img / 2 + 0.5)\n",
        "\n",
        "        # set up measurement\n",
        "        if measure_config['operator']['name'] == 'inpainting':\n",
        "            # you can keep your partial(...) pathway if used elsewhere\n",
        "            y = operator.forward(ref_img, mask=mask)\n",
        "        else:\n",
        "            y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)  # measured magnitude domain used in losses/MCE\n",
        "\n",
        "        print(f\"\\nReconstructing Image {filename}...\")\n",
        "        for run_iter in range(num_runs):\n",
        "            print(f\"  Run {run_iter+1}/{num_runs}\")\n",
        "\n",
        "            # ----- initialize x_T -----\n",
        "            x0_init = torch.randn((1, 3, 256, 256), device=device, dtype=dtype)\n",
        "            x_T = to_start_latent_from_x0(\n",
        "                x0_init, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T, noise_scale=1.0\n",
        "            )\n",
        "\n",
        "            best_mce_overall = float('inf')\n",
        "            best_psnr_overall = -float('inf')\n",
        "            best_final_image = None\n",
        "\n",
        "            restart = 0\n",
        "            no_improve = 0\n",
        "            while True:\n",
        "                # one full pass over all timesteps\n",
        "                measurement_errors = []\n",
        "                input_t = x_T.clone()\n",
        "\n",
        "                for i, t in enumerate(scheduler.timesteps):\n",
        "                    prev_timestep = int(t) - step_size\n",
        "                    alpha_prod_t = scheduler.alphas_cumprod[int(t)]\n",
        "                    alpha_prod_t_prev = (\n",
        "                        scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0\n",
        "                        else scheduler.alphas_cumprod[0]\n",
        "                    )\n",
        "                    beta_prod_t = 1 - alpha_prod_t\n",
        "                    sqrt_one_minus_alpha_cumprod = beta_prod_t**0.5\n",
        "                    sqrt_alpha_cumprod = alpha_prod_t**0.5\n",
        "                    sqrt_alpha_cumprod_prev = alpha_prod_t_prev**0.5\n",
        "\n",
        "                    input_t, pred_x0, noise_pred = optimize_input(\n",
        "                        input_t, sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod,\n",
        "                        int(t), y_n, num_steps=inner_opt_steps, learning_rate=inner_lr\n",
        "                    )\n",
        "\n",
        "                    # phase image in [0,1]\n",
        "                    phase_image = (pred_x0 / 2 + 0.5).clamp(0, 1)\n",
        "                    mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "                    measurement_errors.append(mce)\n",
        "                    print(f\"    t={int(t):4d}  MCE={mce:.6f}\")\n",
        "\n",
        "                    # DDIM/ODE next-step latent (ancestral)\n",
        "                    eps = torch.randn_like(input_t)\n",
        "                    input_t = sqrt_alpha_cumprod_prev * pred_x0 + (1 - alpha_prod_t_prev)**0.5 * eps\n",
        "\n",
        "                    # threshold trigger: restart ASAP with warm-start if met\n",
        "                    if mce >= mce_threshold:\n",
        "                        print(f\"    *** threshold hit ({mce:.6f} ≤ {mce_threshold}) → scheduling restart\")\n",
        "                        # prepare new x_T from current x0 (pred_x0)\n",
        "                        x_T = to_start_latent_from_x0(\n",
        "                            pred_x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T,\n",
        "                            noise_scale=restart_noise_scale\n",
        "                        )\n",
        "                        break  # break this pass early to restart\n",
        "\n",
        "                # end of pass: compute final image & stats of this pass\n",
        "                final_x0 = pred_x0.detach()\n",
        "                final_img = (final_x0 / 2 + 0.5).clamp(0, 1).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                gt_img_np = gt[0].permute(1, 2, 0).detach().cpu().numpy()\n",
        "                final_psnr = compute_psnr(final_img, gt_img_np)\n",
        "                final_mce = measurement_errors[-1] if len(measurement_errors) else float('inf')\n",
        "                min_mce_pass = min(measurement_errors) if len(measurement_errors) else float('inf')\n",
        "\n",
        "                print(f\"    Pass done: final MCE={final_mce:.6f}  min-pass MCE={min_mce_pass:.6f}  PSNR={final_psnr:.3f} dB\")\n",
        "\n",
        "                # track best across restarts (by min MCE in the pass)\n",
        "                improved = min_mce_pass < best_mce_overall - 1e-9\n",
        "                if improved:\n",
        "                    best_mce_overall = min_mce_pass\n",
        "                    best_psnr_overall = final_psnr\n",
        "                    best_final_image = final_img\n",
        "                    no_improve = 0\n",
        "                else:\n",
        "                    no_improve += 1\n",
        "\n",
        "                # stopping conditions for restarts\n",
        "                hit_threshold = (min_mce_pass <= mce_threshold)\n",
        "                if stop_on_hit and hit_threshold:\n",
        "                    print(\"    Stopping on first hit.\")\n",
        "                    break\n",
        "                if restart >= max_restarts:\n",
        "                    print(\"    Max restarts reached.\")\n",
        "                    break\n",
        "                if patience_restarts is not None and no_improve >= patience_restarts:\n",
        "                    print(\"    Early stop: no improvement across restarts.\")\n",
        "                    break\n",
        "\n",
        "                # otherwise: prepare next restart if threshold was hit inside the pass\n",
        "                restart += 1\n",
        "                if not hit_threshold:\n",
        "                    # even if not hit, we can still warm-start next pass from best x0 of this pass\n",
        "                    x_T = to_start_latent_from_x0(\n",
        "                        final_x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T,\n",
        "                        noise_scale=restart_noise_scale\n",
        "                    )\n",
        "                    print(f\"    Restarting (no threshold hit). Restart #{restart}\")\n",
        "\n",
        "            # record final stats for this run (use the best of the restarts)\n",
        "            results_table.append({\n",
        "                \"image\": filename,\n",
        "                \"run\": run_iter,\n",
        "                \"best_mce_overall\": best_mce_overall,\n",
        "                \"best_psnr_overall\": best_psnr_overall,\n",
        "                \"max_restarts\": max_restarts,\n",
        "                \"restart_noise_scale\": restart_noise_scale,\n",
        "                \"threshold\": mce_threshold,\n",
        "                \"n_steps\": n_step,\n",
        "            })\n",
        "            print(f\"  ==> Best-overall for run: MCE={best_mce_overall:.6f}, PSNR={best_psnr_overall:.3f} dB\")\n",
        "\n",
        "    # correlation check across all images/runs\n",
        "    mces = np.array([r[\"best_mce_overall\"] for r in results_table], dtype=float)\n",
        "    psnrs = np.array([r[\"best_psnr_overall\"] for r in results_table], dtype=float)\n",
        "    if len(mces) >= 2 and np.std(mces) > 0 and np.std(psnrs) > 0:\n",
        "        corr = float(np.corrcoef(mces, psnrs)[0,1])\n",
        "    else:\n",
        "        corr = float('nan')\n",
        "\n",
        "    print(\"\\n=== Summary ===\")\n",
        "    print(f\"Runs (total): {len(results_table)}\")\n",
        "    print(f\"Pearson corr(best_MCE, best_PSNR): {corr:.4f} (expect negative if smaller MCE → higher PSNR)\")\n",
        "    return results_table, corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c90e012",
      "metadata": {
        "id": "0c90e012"
      },
      "outputs": [],
      "source": [
        "results, corr = run_threshold_restart_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b27195e",
      "metadata": {
        "id": "7b27195e"
      },
      "outputs": [],
      "source": [
        "# --- Add these helpers somewhere below the experiment function ---\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def save_results_to_csv(results_table, csv_path=\"threshold_restart_results_con.csv\"):\n",
        "    \"\"\"\n",
        "    Save the per-run summary rows returned by run_threshold_restart_experiment()\n",
        "    to a CSV. Each row contains: image, run, best_mce_overall, best_psnr_overall, etc.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(results_table)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    print(f\"Saved {len(df)} rows to {csv_path}\")\n",
        "    return csv_path\n",
        "\n",
        "def plot_psnr_vs_mce(results_table, png_path=\"psnr_vs_mce_con.png\"):\n",
        "    \"\"\"\n",
        "    Scatter plot of best PSNR [dB] vs best MCE (lower is better).\n",
        "    Annotates Pearson correlation r in the title.\n",
        "    \"\"\"\n",
        "    mces  = np.array([r[\"best_mce_overall\"]  for r in results_table], dtype=float)\n",
        "    psnrs = np.array([r[\"best_psnr_overall\"] for r in results_table], dtype=float)\n",
        "\n",
        "    # guard against degenerate cases\n",
        "    if len(mces) < 2 or np.std(mces) == 0 or np.std(psnrs) == 0:\n",
        "        r = float('nan')\n",
        "    else:\n",
        "        r = float(np.corrcoef(mces, psnrs)[0, 1])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.scatter(mces, psnrs, s=16)\n",
        "    plt.xlabel(\"Best MCE (lower is better)\")\n",
        "    plt.ylabel(\"Best PSNR [dB] (higher is better)\")\n",
        "    plt.title(f\"PSNR vs MCE (Pearson r = {r:.3f}, n = {len(mces)})\")\n",
        "    plt.grid(True, linestyle=\"--\", linewidth=0.5, alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(png_path, dpi=150)\n",
        "    plt.close()\n",
        "    print(f\"Saved scatter plot to {png_path} (r = {r:.3f})\")\n",
        "    return png_path, r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d07e2bf",
      "metadata": {
        "id": "5d07e2bf"
      },
      "outputs": [],
      "source": [
        "csv_path = save_results_to_csv(results)          # -> \"threshold_restart_results.csv\"\n",
        "png_path, r = plot_psnr_vs_mce(results)          # -> \"psnr_vs_mce.png\", correlation value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86ea7d1",
      "metadata": {
        "id": "a86ea7d1"
      },
      "outputs": [],
      "source": [
        "import os, torch, numpy as np, torchvision\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "\n",
        "# ===== Helpers (same API as before) =====\n",
        "\n",
        "def compute_mce(reconstructed_image, measured_magnitude, target_shape=None):\n",
        "    x_hat = reconstructed_image.clamp(0, 1)\n",
        "    if target_shape is not None:\n",
        "        _, _, H, W = x_hat.shape\n",
        "        target_H, target_W = target_shape[-2], target_shape[-1]\n",
        "        pad_h = (target_H - H) // 2\n",
        "        pad_w = (target_W - W) // 2\n",
        "        x_hat = F.pad(x_hat, (pad_w, pad_w, pad_h, pad_h))\n",
        "    if not torch.is_complex(x_hat):\n",
        "        x_hat = x_hat.type(torch.complex64)\n",
        "    fft_x_hat = torch.view_as_complex(fft2c_new(torch.view_as_real(x_hat)))\n",
        "    return (fft_x_hat.abs() - measured_magnitude).pow(2).mean().item()\n",
        "\n",
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse <= 0:\n",
        "        return float('inf')\n",
        "    return float(20 * np.log10(1.0 / (mse**0.5)))\n",
        "\n",
        "@torch.no_grad()\n",
        "def to_start_latent_from_x0(x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T, noise_scale=1.0):\n",
        "    eps = torch.randn_like(x0) * noise_scale\n",
        "    return sqrt_alpha_bar_T * x0 + sqrt_one_minus_alpha_bar_T * eps\n",
        "\n",
        "def optimize_input(\n",
        "    input_tensor, sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod, t, y_n,\n",
        "    num_steps=20, learning_rate=0.075\n",
        "):\n",
        "    \"\"\"\n",
        "    One inner optimization block producing (x_t_next, pred_x0, noise_pred).\n",
        "    Assumes global: `model` on correct device, expects (x_t, t_long).\n",
        "    \"\"\"\n",
        "    x_t = input_tensor.clone().detach().requires_grad_(True)\n",
        "    opt = torch.optim.Adam([x_t], lr=learning_rate)\n",
        "    tt = (torch.ones(1, device=x_t.device, dtype=torch.long) * int(t))\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        opt.zero_grad()\n",
        "        noise_pred = model(x_t, tt)[:, :3]\n",
        "        pred_x0 = (x_t - sqrt_one_minus_alpha_cumprod * noise_pred) / sqrt_alpha_cumprod\n",
        "        pred_x0 = torch.clamp(pred_x0, -1, 1)\n",
        "\n",
        "        # data term in magnitude space (mirror the inner-loop forward exactly)\n",
        "        pad = int((2 / 8.0) * 256)\n",
        "        x = pred_x0 * 0.5 + 0.5\n",
        "        x = F.pad(x, (pad, pad, pad, pad))\n",
        "        if not torch.is_complex(x):\n",
        "            x = x.type(torch.complex64)\n",
        "        fft2_m = torch.view_as_complex(fft2c_new(torch.view_as_real(x)))\n",
        "        out_mag = fft2_m.abs()\n",
        "\n",
        "        data_loss = torch.norm(out_mag - y_n)**2\n",
        "        reg_loss = 0.1 * torch.norm(input_tensor.detach() - x_t)**2\n",
        "        loss = data_loss + reg_loss\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    noise = (x_t - sqrt_alpha_cumprod * pred_x0) / sqrt_one_minus_alpha_cumprod\n",
        "    return x_t.detach(), pred_x0.detach(), noise.detach()\n",
        "\n",
        "# ===== Main: end-of-pass restart logic (Path A) =====\n",
        "\n",
        "def run_threshold_restart_experiment(\n",
        "    image_indices=range(11, 12),\n",
        "    num_runs=1,\n",
        "    n_step=20,\n",
        "    mce_threshold=0.0015,\n",
        "    restart_policy=\"bad_warm\",     # \"good_refine\" | \"bad_warm\" | \"bad_random\"\n",
        "    max_restarts=10,\n",
        "    patience_restarts=None,        # e.g., 2: stop if best MCE doesn't improve across this many restarts\n",
        "    restart_noise_scale=0.5,      # used for warm starts\n",
        "    inner_opt_steps=20,\n",
        "    inner_lr=0.075,\n",
        "    seed=0,\n",
        "):\n",
        "    \"\"\"\n",
        "    End-of-pass decision only. No step-level restarts.\n",
        "    Requires globals: model, device, operator, noiser, measure_config, fft2c_new, ifft2c_new, DDIMScheduler\n",
        "    \"\"\"\n",
        "    # reproducibility\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "\n",
        "    scheduler = DDIMScheduler()\n",
        "    scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "    step_size = 1000 // n_step\n",
        "\n",
        "    dtype = torch.float32\n",
        "    results_table = []\n",
        "\n",
        "    # Precompute start-time alphas (largest t in schedule)\n",
        "    T = int(scheduler.timesteps[0].item())\n",
        "    alpha_bar_T = scheduler.alphas_cumprod[T].item()\n",
        "    sqrt_alpha_bar_T = alpha_bar_T**0.5\n",
        "    sqrt_one_minus_alpha_bar_T = (1.0 - alpha_bar_T)**0.5\n",
        "\n",
        "    for j in image_indices:\n",
        "        filename = f\"{j:05d}.png\"\n",
        "        filepath = os.path.join(\n",
        "            \"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\",\n",
        "            filename\n",
        "        )\n",
        "        gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "        ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "        x = ref_numpy * 2 - 1\n",
        "        x = x.transpose(2, 0, 1)\n",
        "        ref_img = torch.tensor(x, dtype=dtype, device=device).unsqueeze(0)\n",
        "        gt = (ref_img / 2 + 0.5)\n",
        "\n",
        "        # forward/measurement\n",
        "        if measure_config['operator']['name'] == 'inpainting':\n",
        "            y = operator.forward(ref_img, mask=mask)\n",
        "        else:\n",
        "            y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)\n",
        "\n",
        "        print(f\"\\nReconstructing Image {filename}...\")\n",
        "        for run_iter in range(num_runs):\n",
        "            print(f\"  Run {run_iter+1}/{num_runs}\")\n",
        "\n",
        "            # initial latent x_T (random)\n",
        "            x0_init = torch.randn((1, 3, 256, 256), device=device, dtype=dtype)\n",
        "            x_T = to_start_latent_from_x0(x0_init, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T, noise_scale=1.0)\n",
        "\n",
        "            best_mce_overall = float('inf')\n",
        "            best_psnr_overall = -float('inf')\n",
        "            best_final_image = None\n",
        "            no_improve = 0\n",
        "            restart = 0\n",
        "            passes_used = 0\n",
        "\n",
        "            while True:\n",
        "                measurement_errors = []\n",
        "                input_t = x_T.clone()\n",
        "                passes_used += 1\n",
        "\n",
        "                # ===== Full pass over the schedule; NO step-level restarts =====\n",
        "                for i, t in enumerate(scheduler.timesteps):\n",
        "                    prev_timestep = int(t) - step_size\n",
        "                    alpha_prod_t = scheduler.alphas_cumprod[int(t)]\n",
        "                    alpha_prod_t_prev = (\n",
        "                        scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0\n",
        "                        else scheduler.alphas_cumprod[0]\n",
        "                    )\n",
        "                    beta_prod_t = 1 - alpha_prod_t\n",
        "                    sqrt_one_minus_alpha_cumprod = beta_prod_t**0.5\n",
        "                    sqrt_alpha_cumprod = alpha_prod_t**0.5\n",
        "                    sqrt_alpha_cumprod_prev = alpha_prod_t_prev**0.5\n",
        "\n",
        "                    input_t, pred_x0, noise_pred = optimize_input(\n",
        "                        input_t, sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod,\n",
        "                        int(t), y_n, num_steps=inner_opt_steps, learning_rate=inner_lr\n",
        "                    )\n",
        "\n",
        "                    phase_image = (pred_x0 / 2 + 0.5).clamp(0, 1)\n",
        "                    mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "                    measurement_errors.append(mce)\n",
        "                    print(f\"    t={int(t):4d}  MCE={mce:.6f}\")\n",
        "\n",
        "                    # ancestral move to previous timestep latent\n",
        "                    eps = torch.randn_like(input_t)\n",
        "                    input_t = sqrt_alpha_cumprod_prev * pred_x0 + (1 - alpha_prod_t_prev)**0.5 * eps\n",
        "\n",
        "                # ===== End-of-pass statistics & decision =====\n",
        "                final_x0 = pred_x0.detach()\n",
        "                final_img = (final_x0 / 2 + 0.5).clamp(0, 1).squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                gt_img_np = gt[0].permute(1, 2, 0).detach().cpu().numpy()\n",
        "                final_psnr = compute_psnr(final_img, gt_img_np)\n",
        "                final_mce  = measurement_errors[-1] if measurement_errors else float('inf')\n",
        "                min_mce_pass = min(measurement_errors) if measurement_errors else float('inf')\n",
        "\n",
        "                print(f\"    Pass done: final MCE={final_mce:.6f}  min-pass MCE={min_mce_pass:.6f}  PSNR={final_psnr:.3f} dB\")\n",
        "\n",
        "                # track best across passes\n",
        "                improved = min_mce_pass < best_mce_overall - 1e-12\n",
        "                if improved:\n",
        "                    best_mce_overall = min_mce_pass\n",
        "                    best_psnr_overall = final_psnr\n",
        "                    best_final_image = final_img\n",
        "                    no_improve = 0\n",
        "                else:\n",
        "                    no_improve += 1\n",
        "\n",
        "                # decide whether to restart another pass (END-OF-PASS ONLY)\n",
        "                trigger = False\n",
        "                if restart_policy == \"good_refine\":\n",
        "                    trigger = (min_mce_pass <= mce_threshold)\n",
        "                elif restart_policy in (\"bad_warm\", \"bad_random\"):\n",
        "                    trigger = (min_mce_pass >= mce_threshold)\n",
        "\n",
        "                # patience & caps\n",
        "                if patience_restarts is not None and no_improve >= patience_restarts:\n",
        "                    print(\"    Early stop: no improvement across passes.\")\n",
        "                    break\n",
        "                if restart >= max_restarts:\n",
        "                    print(\"    Max restarts reached.\")\n",
        "                    break\n",
        "\n",
        "                if trigger:\n",
        "                    # prepare x_T for the next pass\n",
        "                    if restart_policy in (\"good_refine\", \"bad_warm\"):\n",
        "                        # warm start from this pass's x0\n",
        "                        x_T = to_start_latent_from_x0(\n",
        "                            final_x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T,\n",
        "                            noise_scale=restart_noise_scale\n",
        "                        )\n",
        "                        print(f\"    Restarting (policy={restart_policy}).\")\n",
        "                    else:  # bad_random\n",
        "                        x_T = torch.randn_like(x_T)\n",
        "                        print(\"    Restarting (policy=bad_random).\")\n",
        "                    restart += 1\n",
        "                    continue  # run another full pass\n",
        "                else:\n",
        "                    # stop passes for this run\n",
        "                    break\n",
        "\n",
        "            # record best-overall for this (image, run)\n",
        "            results_table.append({\n",
        "                \"image\": filename,\n",
        "                \"run\": run_iter,\n",
        "                \"best_mce_overall\": best_mce_overall,\n",
        "                \"best_psnr_overall\": best_psnr_overall,\n",
        "                \"max_restarts\": max_restarts,\n",
        "                \"restart_noise_scale\": restart_noise_scale,\n",
        "                \"threshold\": mce_threshold,\n",
        "                \"n_steps\": n_step,\n",
        "                \"restart_policy\": restart_policy,\n",
        "                \"passes_used\": passes_used,\n",
        "            })\n",
        "            print(f\"  ==> Best-overall for run: MCE={best_mce_overall:.6f}, PSNR={best_psnr_overall:.3f} dB\")\n",
        "\n",
        "    # correlation across all (image, run)\n",
        "    mces  = np.array([r[\"best_mce_overall\"]  for r in results_table], dtype=float)\n",
        "    psnrs = np.array([r[\"best_psnr_overall\"] for r in results_table], dtype=float)\n",
        "    if len(mces) >= 2 and np.std(mces) > 0 and np.std(psnrs) > 0:\n",
        "        corr = float(np.corrcoef(mces, psnrs)[0,1])\n",
        "    else:\n",
        "        corr = float('nan')\n",
        "\n",
        "    print(\"\\n=== Summary ===\")\n",
        "    print(f\"Runs (total): {len(results_table)}\")\n",
        "    print(f\"Pearson corr(best_MCE, best_PSNR): {corr:.4f} (expect negative if smaller MCE → higher PSNR)\")\n",
        "    return results_table, corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a262d75",
      "metadata": {
        "id": "4a262d75"
      },
      "outputs": [],
      "source": [
        "run_threshold_restart_experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d18d219a",
      "metadata": {
        "id": "d18d219a"
      },
      "outputs": [],
      "source": [
        "def _summarize_runs(results):\n",
        "    import numpy as np\n",
        "    if not results:\n",
        "        return {\"n\": 0, \"mean_best_mce\": float('nan'), \"median_best_mce\": float('nan'),\n",
        "                \"mean_best_psnr\": float('nan'), \"median_best_psnr\": float('nan'),\n",
        "                \"pct_hits_threshold\": float('nan'), \"mean_passes_used\": float('nan')}\n",
        "    mces   = np.array([r[\"best_mce_overall\"] for r in results], dtype=float)\n",
        "    psnrs  = np.array([r[\"best_psnr_overall\"] for r in results], dtype=float)\n",
        "    thr    = np.array([r[\"threshold\"] for r in results], dtype=float)\n",
        "    hits   = (mces <= thr)\n",
        "    passes = np.array([r.get(\"passes_used\", np.nan) for r in results], dtype=float)\n",
        "    return {\n",
        "        \"n\": len(results),\n",
        "        \"mean_best_mce\": float(np.nanmean(mces)),\n",
        "        \"median_best_mce\": float(np.nanmedian(mces)),\n",
        "        \"mean_best_psnr\": float(np.nanmean(psnrs)),\n",
        "        \"median_best_psnr\": float(np.nanmedian(psnrs)),\n",
        "        \"pct_hits_threshold\": float(100.0 * hits.mean()),\n",
        "        \"mean_passes_used\": float(np.nanmean(passes)),\n",
        "    }\n",
        "\n",
        "def ab_compare_parity_10_passes(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20,\n",
        "    # inner loop config\n",
        "    inner_opt_steps=20,\n",
        "    inner_lr=0.075,\n",
        "    # asymmetric thresholds\n",
        "    good_refine_threshold=0.0016,  # looser: refine “decent” passes\n",
        "    bad_warm_threshold=0.0013,     # tighter: only salvage truly-bad passes\n",
        "    # warm-start noise\n",
        "    good_refine_noise=0.5,\n",
        "    bad_warm_noise=0.5,\n",
        "    seed=123,\n",
        "):\n",
        "    \"\"\"\n",
        "    Apples-to-apples: ~10 full passes total per variant.\n",
        "\n",
        "    - baseline_no_restarts: num_runs=10, max_restarts=0         -> 10 passes\n",
        "    - good_refine:         num_runs=1,  max_restarts=9          -> up to 10 passes\n",
        "    - bad_warm:            num_runs=1,  max_restarts=9          -> up to 10 passes\n",
        "    \"\"\"\n",
        "    shared_base = dict(\n",
        "        image_indices=image_indices,\n",
        "        n_step=n_step,\n",
        "        inner_opt_steps=inner_opt_steps,\n",
        "        inner_lr=inner_lr,\n",
        "        seed=seed,\n",
        "        patience_restarts=None,  # keep simple for parity\n",
        "    )\n",
        "\n",
        "    # --- baseline: 10 independent inits (10 passes) ---\n",
        "    print(\"\\n=== baseline_no_restarts (10 inits) ===\")\n",
        "    base_res, base_corr = run_threshold_restart_experiment(\n",
        "        **shared_base,\n",
        "        num_runs=10,\n",
        "        restart_policy=\"bad_warm\",        # irrelevant when max_restarts=0\n",
        "        mce_threshold=bad_warm_threshold, # for consistent logging\n",
        "        restart_noise_scale=0.0,\n",
        "        max_restarts=0\n",
        "    )\n",
        "    base_sum = _summarize_runs(base_res); base_sum[\"name\"] = \"baseline_no_restarts\"; base_sum[\"corr\"] = base_corr\n",
        "\n",
        "    # --- good_refine: 1 run, ≤10 passes ---\n",
        "    print(\"\\n=== good_refine (1 run, ≤10 passes) ===\")\n",
        "    gr_res, gr_corr = run_threshold_restart_experiment(\n",
        "        **shared_base,\n",
        "        num_runs=1,\n",
        "        restart_policy=\"good_refine\",\n",
        "        mce_threshold=good_refine_threshold,\n",
        "        restart_noise_scale=good_refine_noise,\n",
        "        max_restarts=9\n",
        "    )\n",
        "    gr_sum = _summarize_runs(gr_res); gr_sum[\"name\"] = \"good_refine\"; gr_sum[\"corr\"] = gr_corr\n",
        "\n",
        "    # --- bad_warm: 1 run, ≤10 passes ---\n",
        "    print(\"\\n=== bad_warm (1 run, ≤10 passes) ===\")\n",
        "    bw_res, bw_corr = run_threshold_restart_experiment(\n",
        "        **shared_base,\n",
        "        num_runs=1,\n",
        "        restart_policy=\"bad_warm\",\n",
        "        mce_threshold=bad_warm_threshold,\n",
        "        restart_noise_scale=bad_warm_noise,\n",
        "        max_restarts=9\n",
        "    )\n",
        "    bw_sum = _summarize_runs(bw_res); bw_sum[\"name\"] = \"bad_warm\"; bw_sum[\"corr\"] = bw_corr\n",
        "\n",
        "    # --- summary table ---\n",
        "    print(\"\\n=== A/B Summary (≈10 passes per variant) ===\")\n",
        "    for s in (base_sum, gr_sum, bw_sum):\n",
        "        print(f\"{s['name']:>20} | n={s['n']:>3} | mean MCE={s['mean_best_mce']:.6f} \"\n",
        "              f\"| mean PSNR={s['mean_best_psnr']:.3f} dB | hits≤thr={s['pct_hits_threshold']:.1f}% \"\n",
        "              f\"| mean passes={s['mean_passes_used']:.2f} | corr(MCE,PSNR)={s['corr']:.3f}\")\n",
        "\n",
        "    return {\n",
        "        \"baseline\": (base_res, base_sum, base_corr),\n",
        "        \"good_refine\": (gr_res, gr_sum, gr_corr),\n",
        "        \"bad_warm\": (bw_res, bw_sum, bw_corr),\n",
        "    }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a5231f8",
      "metadata": {
        "id": "3a5231f8"
      },
      "outputs": [],
      "source": [
        "ab_out = ab_compare_parity_10_passes(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20,\n",
        "    good_refine_threshold=0.0016,\n",
        "    bad_warm_threshold=0.0013,\n",
        "    good_refine_noise=0.5,\n",
        "    bad_warm_noise=0.5,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9579bfda",
      "metadata": {
        "id": "9579bfda"
      },
      "source": [
        "## A/B Testing ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6a24a9d",
      "metadata": {
        "id": "e6a24a9d"
      },
      "outputs": [],
      "source": [
        "def run_fixed_pass_experiment(\n",
        "    image_indices=range(11,14),\n",
        "    num_runs=1,\n",
        "    n_step=20,\n",
        "    total_passes=10,                 # <- enforces exactly this many passes per run\n",
        "    policy=\"good_refine\",            # \"baseline_random\" | \"good_refine\" | \"bad_warm\"\n",
        "    mce_threshold=0.0015,\n",
        "    restart_noise_scale=0.5,         # warm-start noise\n",
        "    inner_opt_steps=20,\n",
        "    inner_lr=0.075,\n",
        "    seed=0,\n",
        "):\n",
        "    \"\"\"\n",
        "    EXACTLY `total_passes` per run. No early exits.\n",
        "    Policies:\n",
        "      - baseline_random: every pass is fresh random init (equiv. to 10 random inits).\n",
        "      - good_refine:     if pass hits (min_mce_pass <= thr)  -> warm-start next; else random.\n",
        "      - bad_warm:        if pass NOT hit (min_mce_pass > thr)-> warm-start next; else random.\n",
        "    \"\"\"\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "\n",
        "    scheduler = DDIMScheduler()\n",
        "    scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "    step_size = 1000 // n_step\n",
        "    dtype = torch.float32\n",
        "\n",
        "    # Start-time alphas (largest t)\n",
        "    T = int(scheduler.timesteps[0].item())\n",
        "    alpha_bar_T = scheduler.alphas_cumprod[T].item()\n",
        "    sqrt_alpha_bar_T = alpha_bar_T**0.5\n",
        "    sqrt_one_minus_alpha_bar_T = (1.0 - alpha_bar_T)**0.5\n",
        "\n",
        "    def _random_xT_like(shape, device, dtype):\n",
        "        x0_init = torch.randn(shape, device=device, dtype=dtype)\n",
        "        return to_start_latent_from_x0(x0_init, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T, noise_scale=1.0)\n",
        "\n",
        "    results_table = []\n",
        "\n",
        "    for j in image_indices:\n",
        "        filename = f\"{j:05d}.png\"\n",
        "        filepath = os.path.join(\n",
        "            \"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\",\n",
        "            filename\n",
        "        )\n",
        "        gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "        ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "        x = (ref_numpy * 2 - 1).transpose(2, 0, 1)\n",
        "        ref_img = torch.tensor(x, dtype=dtype, device=device).unsqueeze(0)\n",
        "        gt = (ref_img/2+0.5)\n",
        "\n",
        "        # forward/measurement (no GT leakage)\n",
        "        if measure_config['operator']['name'] == 'inpainting':\n",
        "            y = operator.forward(ref_img, mask=mask)\n",
        "        else:\n",
        "            y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)\n",
        "\n",
        "        print(f\"\\n[FIXED-PASSES:{policy}] Image {filename}\")\n",
        "        for run_iter in range(num_runs):\n",
        "            print(f\"  Run {run_iter+1}/{num_runs}\")\n",
        "\n",
        "            # initialize starting x_T depending on policy\n",
        "            x_T = _random_xT_like((1,3,256,256), device, dtype)\n",
        "\n",
        "            best_mce_overall = float('inf')\n",
        "            best_psnr_overall = -float('inf')\n",
        "            best_final_image = None\n",
        "\n",
        "            passes_used = 0\n",
        "\n",
        "            for pass_idx in range(total_passes):\n",
        "                passes_used += 1\n",
        "                measurement_errors = []\n",
        "                input_t = x_T.clone()\n",
        "\n",
        "                # --- full reverse pass ---\n",
        "                for t in scheduler.timesteps:\n",
        "                    t = int(t)\n",
        "                    prev_timestep = t - step_size\n",
        "                    alpha_t = scheduler.alphas_cumprod[t]\n",
        "                    alpha_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "                    sqrt_one_minus = (1 - alpha_t)**0.5\n",
        "                    sqrt_alpha = alpha_t**0.5\n",
        "                    sqrt_alpha_prev = alpha_prev**0.5\n",
        "\n",
        "                    input_t, pred_x0, _ = optimize_input(\n",
        "                        input_t, sqrt_one_minus, sqrt_alpha, t, y_n,\n",
        "                        num_steps=inner_opt_steps, learning_rate=inner_lr\n",
        "                    )\n",
        "\n",
        "                    phase_image = (pred_x0/2+0.5).clamp(0,1)\n",
        "                    mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "                    measurement_errors.append(mce)\n",
        "\n",
        "                    # ancestral step\n",
        "                    eps = torch.randn_like(input_t)\n",
        "                    input_t = sqrt_alpha_prev * pred_x0 + (1 - alpha_prev)**0.5 * eps\n",
        "\n",
        "                # --- end-of-pass stats ---\n",
        "                final_x0 = pred_x0.detach()\n",
        "                final_img = (final_x0/2+0.5).clamp(0,1).squeeze(0).permute(1,2,0).cpu().numpy()\n",
        "                gt_img_np = gt[0].permute(1,2,0).detach().cpu().numpy()\n",
        "                final_psnr = compute_psnr(final_img, gt_img_np)\n",
        "                min_mce_pass = min(measurement_errors) if measurement_errors else float('inf')\n",
        "\n",
        "                print(f\"    Pass {pass_idx+1}/{total_passes}: min-pass MCE={min_mce_pass:.6f}  PSNR={final_psnr:.3f} dB\")\n",
        "\n",
        "                # track best across all passes\n",
        "                if min_mce_pass < best_mce_overall - 1e-12:\n",
        "                    best_mce_overall = min_mce_pass\n",
        "                    best_psnr_overall = final_psnr\n",
        "                    best_final_image = final_img\n",
        "\n",
        "                # --- choose next x_T based on policy (ALWAYS do next pass unless last) ---\n",
        "                if pass_idx < total_passes - 1:\n",
        "                    if policy == \"baseline_random\":\n",
        "                        # always random\n",
        "                        x_T = _random_xT_like((1,3,256,256), device, dtype)\n",
        "\n",
        "                    elif policy == \"good_refine\":\n",
        "                        if min_mce_pass <= mce_threshold:\n",
        "                            # threshold HIT => warm-start from current x0\n",
        "                            x_T = to_start_latent_from_x0(final_x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T,\n",
        "                                                          noise_scale=restart_noise_scale)\n",
        "                            print(\"      -> HIT thr → warm-start next pass\")\n",
        "                        else:\n",
        "                            # threshold NOT hit => random\n",
        "                            x_T = _random_xT_like((1,3,256,256), device, dtype)\n",
        "                            print(\"      -> NOT hit thr → random next pass\")\n",
        "\n",
        "                    elif policy == \"bad_warm\":\n",
        "                        if min_mce_pass > mce_threshold:\n",
        "                            # threshold NOT hit => warm start\n",
        "                            x_T = to_start_latent_from_x0(final_x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T,\n",
        "                                                          noise_scale=restart_noise_scale)\n",
        "                            print(\"      -> NOT hit thr → warm-start next pass\")\n",
        "                        else:\n",
        "                            # threshold HIT => random\n",
        "                            x_T = _random_xT_like((1,3,256,256), device, dtype)\n",
        "                            print(\"      -> HIT thr → random next pass\")\n",
        "\n",
        "                    else:\n",
        "                        raise ValueError(f\"Unknown policy: {policy}\")\n",
        "\n",
        "            # append per (image, run)\n",
        "            results_table.append({\n",
        "                \"image\": filename,\n",
        "                \"run\": run_iter,\n",
        "                \"best_mce_overall\": float(best_mce_overall),\n",
        "                \"best_psnr_overall\": float(best_psnr_overall),\n",
        "                \"policy\": policy,\n",
        "                \"threshold\": float(mce_threshold),\n",
        "                \"n_steps\": int(n_step),\n",
        "                \"passes_used\": int(passes_used),   # should equal total_passes\n",
        "                \"total_passes\": int(total_passes),\n",
        "                \"restart_noise_scale\": float(restart_noise_scale),\n",
        "            })\n",
        "            print(f\"  ==> Best-overall: MCE={best_mce_overall:.6f}, PSNR={best_psnr_overall:.3f} dB \"\n",
        "                  f\"(passes={passes_used})\")\n",
        "\n",
        "    # global correlation across all rows\n",
        "    mces  = np.array([r[\"best_mce_overall\"]  for r in results_table], dtype=float)\n",
        "    psnrs = np.array([r[\"best_psnr_overall\"] for r in results_table], dtype=float)\n",
        "    corr = float('nan') if len(mces)<2 or np.std(mces)==0 or np.std(psnrs)==0 else float(np.corrcoef(mces, psnrs)[0,1])\n",
        "\n",
        "    print(\"\\n=== Fixed-Passes Summary ===\")\n",
        "    print(f\"Rows (image×run): {len(results_table)}\")\n",
        "    print(f\"Pearson corr(best_MCE, best_PSNR): {corr:.4f}\")\n",
        "    return results_table, corr\n",
        "\n",
        "def compute_mce(reconstructed_image, measured_magnitude, target_shape=None):\n",
        "    x_hat = reconstructed_image.clamp(0, 1)\n",
        "    if target_shape is not None:\n",
        "        _, _, H, W = x_hat.shape\n",
        "        target_H, target_W = target_shape[-2], target_shape[-1]\n",
        "        pad_h = (target_H - H) // 2\n",
        "        pad_w = (target_W - W) // 2\n",
        "        x_hat = F.pad(x_hat, (pad_w, pad_w, pad_h, pad_h))\n",
        "    if not torch.is_complex(x_hat):\n",
        "        x_hat = x_hat.type(torch.complex64)\n",
        "    fft_x_hat = torch.view_as_complex(fft2c_new(torch.view_as_real(x_hat)))\n",
        "    return (fft_x_hat.abs() - measured_magnitude).pow(2).mean().item()\n",
        "\n",
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse <= 0:\n",
        "        return float('inf')\n",
        "    return float(20 * np.log10(1.0 / (mse**0.5)))\n",
        "\n",
        "@torch.no_grad()\n",
        "def to_start_latent_from_x0(x0, sqrt_alpha_bar_T, sqrt_one_minus_alpha_bar_T, noise_scale=1.0):\n",
        "    eps = torch.randn_like(x0) * noise_scale\n",
        "    return sqrt_alpha_bar_T * x0 + sqrt_one_minus_alpha_bar_T * eps\n",
        "\n",
        "def optimize_input(\n",
        "    input_tensor, sqrt_one_minus_alpha_cumprod, sqrt_alpha_cumprod, t, y_n,\n",
        "    num_steps=20, learning_rate=0.075\n",
        "):\n",
        "    \"\"\"\n",
        "    One inner optimization block producing (x_t_next, pred_x0, noise_pred).\n",
        "    Assumes global: `model` on correct device, expects (x_t, t_long).\n",
        "    \"\"\"\n",
        "    x_t = input_tensor.clone().detach().requires_grad_(True)\n",
        "    opt = torch.optim.Adam([x_t], lr=learning_rate)\n",
        "    tt = (torch.ones(1, device=x_t.device, dtype=torch.long) * int(t))\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        opt.zero_grad()\n",
        "        noise_pred = model(x_t, tt)[:, :3]\n",
        "        pred_x0 = (x_t - sqrt_one_minus_alpha_cumprod * noise_pred) / sqrt_alpha_cumprod\n",
        "        pred_x0 = torch.clamp(pred_x0, -1, 1)\n",
        "\n",
        "        # data term in magnitude space (mirror the inner-loop forward exactly)\n",
        "        pad = int((2 / 8.0) * 256)\n",
        "        x = pred_x0 * 0.5 + 0.5\n",
        "        x = F.pad(x, (pad, pad, pad, pad))\n",
        "        if not torch.is_complex(x):\n",
        "            x = x.type(torch.complex64)\n",
        "        fft2_m = torch.view_as_complex(fft2c_new(torch.view_as_real(x)))\n",
        "        out_mag = fft2_m.abs()\n",
        "\n",
        "        data_loss = torch.norm(out_mag - y_n)**2\n",
        "        reg_loss = 0.1 * torch.norm(input_tensor.detach() - x_t)**2\n",
        "        loss = data_loss + reg_loss\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    noise = (x_t - sqrt_alpha_cumprod * pred_x0) / sqrt_one_minus_alpha_cumprod\n",
        "    return x_t.detach(), pred_x0.detach(), noise.detach()\n",
        "\n",
        "def ab_fixed_passes_10(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20,\n",
        "    total_passes=10,\n",
        "    good_refine_threshold=0.0016,   # looser\n",
        "    bad_warm_threshold=0.0013,      # tighter\n",
        "    restart_noise_scale=0.5,\n",
        "    inner_opt_steps=20,\n",
        "    inner_lr=0.075,\n",
        "    seed=123,\n",
        "):\n",
        "    def summarize(rows, name, corr):\n",
        "        import numpy as np\n",
        "        mces  = np.array([r[\"best_mce_overall\"] for r in rows], dtype=float)\n",
        "        psnrs = np.array([r[\"best_psnr_overall\"] for r in rows], dtype=float)\n",
        "        passes= np.array([r[\"passes_used\"] for r in rows], dtype=float)\n",
        "        print(f\"{name:>18} | n={len(rows):>3} | mean MCE={np.nanmean(mces):.6f} | mean PSNR={np.nanmean(psnrs):.3f} dB \"\n",
        "              f\"| mean passes={np.nanmean(passes):.2f} | corr={corr:.3f}\")\n",
        "\n",
        "    print(\"\\n=== baseline_random (10 passes) ===\")\n",
        "    base_res, base_corr = run_fixed_pass_experiment(\n",
        "        image_indices=image_indices, num_runs=1, n_step=n_step, total_passes=total_passes,\n",
        "        policy=\"baseline_random\", mce_threshold=bad_warm_threshold,  # threshold unused; kept for log symmetry\n",
        "        restart_noise_scale=0.0, inner_opt_steps=inner_opt_steps, inner_lr=inner_lr, seed=seed\n",
        "    )\n",
        "    print(\"\\n=== good_refine (10 passes) ===\")\n",
        "    gr_res, gr_corr = run_fixed_pass_experiment(\n",
        "        image_indices=image_indices, num_runs=1, n_step=n_step, total_passes=total_passes,\n",
        "        policy=\"good_refine\", mce_threshold=good_refine_threshold,\n",
        "        restart_noise_scale=restart_noise_scale, inner_opt_steps=inner_opt_steps, inner_lr=inner_lr, seed=seed\n",
        "    )\n",
        "    print(\"\\n=== bad_warm (10 passes) ===\")\n",
        "    bw_res, bw_corr = run_fixed_pass_experiment(\n",
        "        image_indices=image_indices, num_runs=1, n_step=n_step, total_passes=total_passes,\n",
        "        policy=\"bad_warm\", mce_threshold=bad_warm_threshold,\n",
        "        restart_noise_scale=restart_noise_scale, inner_opt_steps=inner_opt_steps, inner_lr=inner_lr, seed=seed\n",
        "    )\n",
        "\n",
        "    print(\"\\n=== A/B Summary (exactly 10 passes each) ===\")\n",
        "    summarize(base_res, \"baseline_random\", base_corr)\n",
        "    summarize(gr_res,   \"good_refine\",     gr_corr)\n",
        "    summarize(bw_res,   \"bad_warm\",        bw_corr)\n",
        "\n",
        "    return {\n",
        "        \"baseline_random\": base_res,\n",
        "        \"good_refine\": gr_res,\n",
        "        \"bad_warm\": bw_res,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef188ccb",
      "metadata": {
        "id": "ef188ccb"
      },
      "outputs": [],
      "source": [
        "ab_fixed = ab_fixed_passes_10(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20,\n",
        "    total_passes=10,\n",
        "    good_refine_threshold=0.0016,\n",
        "    bad_warm_threshold=0.00147,\n",
        "    restart_noise_scale=0.5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23b70c5a",
      "metadata": {
        "id": "23b70c5a"
      },
      "outputs": [],
      "source": [
        "def make_policy_table_from_dict(ab_results_dict):\n",
        "    \"\"\"\n",
        "    ab_results_dict is what ab_fixed_passes_10(...) returns:\n",
        "      {\n",
        "        \"baseline_random\": [...rows...],\n",
        "        \"good_refine\":     [...rows...],\n",
        "        \"bad_warm\":        [...rows...],\n",
        "      }\n",
        "    Each row must have: 'image', 'best_psnr_overall', 'best_mce_overall'.\n",
        "    \"\"\"\n",
        "    return make_policy_table(\n",
        "        ab_results_dict[\"baseline_random\"],\n",
        "        ab_results_dict[\"good_refine\"],\n",
        "        ab_results_dict[\"bad_warm\"]\n",
        "    )\n",
        "\n",
        "def make_policy_table(base_rows, good_rows, bad_rows):\n",
        "    \"\"\"\n",
        "    Build a table: rows = images, cols = policies (baseline_random, good_refine, bad_warm)\n",
        "    Cell value: \"<best_psnr_overall:.3f} dB (MCE={best_mce_overall:.6f})\"\n",
        "    If multiple runs per image exist, picks the run with max PSNR for that policy.\n",
        "    \"\"\"\n",
        "    by_policy = {\n",
        "        \"baseline_random\": base_rows,\n",
        "        \"good_refine\":     good_rows,\n",
        "        \"bad_warm\":        bad_rows,\n",
        "    }\n",
        "\n",
        "    # collect all images seen\n",
        "    images = sorted(set(\n",
        "        [r[\"image\"] for r in by_policy[\"baseline_random\"]] +\n",
        "        [r[\"image\"] for r in by_policy[\"good_refine\"]] +\n",
        "        [r[\"image\"] for r in by_policy[\"bad_warm\"]]\n",
        "    ))\n",
        "\n",
        "    # build pretty table + numeric companions (optional/useful)\n",
        "    pretty = pd.DataFrame(index=images, columns=list(by_policy.keys()))\n",
        "    psnr_numeric = pd.DataFrame(index=images, columns=list(by_policy.keys()), dtype=float)\n",
        "    mce_numeric  = pd.DataFrame(index=images, columns=list(by_policy.keys()), dtype=float)\n",
        "\n",
        "    for policy, rows in by_policy.items():\n",
        "        # group rows by image\n",
        "        rows_by_img = {}\n",
        "        for r in rows:\n",
        "            rows_by_img.setdefault(r[\"image\"], []).append(r)\n",
        "\n",
        "        for img in images:\n",
        "            if img not in rows_by_img or len(rows_by_img[img]) == 0:\n",
        "                pretty.loc[img, policy] = \"—\"\n",
        "                psnr_numeric.loc[img, policy] = np.nan\n",
        "                mce_numeric.loc[img, policy]  = np.nan\n",
        "                continue\n",
        "\n",
        "            # choose the run with the highest PSNR for this image & policy\n",
        "            best_row = max(rows_by_img[img], key=lambda rr: rr.get(\"best_psnr_overall\", -np.inf))\n",
        "            best_psnr = float(best_row[\"best_psnr_overall\"])\n",
        "            best_mce  = float(best_row[\"best_mce_overall\"])\n",
        "\n",
        "            pretty.loc[img, policy] = f\"{best_psnr:.3f} dB (MCE={best_mce:.6f})\"\n",
        "            psnr_numeric.loc[img, policy] = best_psnr\n",
        "            mce_numeric.loc[img, policy]  = best_mce\n",
        "\n",
        "    return pretty, psnr_numeric, mce_numeric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67170db5",
      "metadata": {
        "id": "67170db5"
      },
      "outputs": [],
      "source": [
        "ab_fixed = ab_fixed_passes_10(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20,\n",
        "    total_passes=10,\n",
        "    good_refine_threshold=0.0016,\n",
        "    bad_warm_threshold=0.0013,\n",
        "    restart_noise_scale=0.5,\n",
        ")\n",
        "pretty, psnr_tbl, mce_tbl = make_policy_table_from_dict(ab_fixed)\n",
        "print(pretty)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bcbc568",
      "metadata": {
        "id": "6bcbc568"
      },
      "source": [
        "## Reburn ##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1b51564",
      "metadata": {
        "id": "f1b51564"
      },
      "outputs": [],
      "source": [
        "def run_fixed_pass_experiment_reburn(\n",
        "    image_indices=range(11,14),\n",
        "    num_runs=1,\n",
        "    n_step=20,\n",
        "    total_passes=10,\n",
        "    policy=\"good_refine\",            # \"baseline_random\" | \"good_refine\" | \"bad_warm\"\n",
        "    mce_threshold=0.0015,\n",
        "    # reburn controls\n",
        "    reburn=True,                     # if False, behavior matches your previous fixed-pass runner\n",
        "    reburn_frac_hit=0.5,             # where to restart (fraction of schedule) when \"hit\" event\n",
        "    reburn_frac_miss=0.7,            # where to restart when \"miss\" event\n",
        "    restart_noise_scale=0.5,         # noise injected at the chosen reburn timestep\n",
        "    # inner optimizer\n",
        "    inner_opt_steps=20,\n",
        "    inner_lr=0.075,\n",
        "    seed=0,\n",
        "    save_dir=None,                   # optional: save best images like before\n",
        "):\n",
        "    \"\"\"\n",
        "    EXACTLY `total_passes` per run. If `reburn=True`, warm-start restarts from an intermediate\n",
        "    timestep t* (chosen by reburn_frac_*), not from the noisiest x_T.\n",
        "\n",
        "    Fractions are in [0,1]:\n",
        "      - 0.0 → start at the VERY END (almost no steps left)\n",
        "      - 1.0 → start at the VERY BEGINNING (most steps left; equivalent to x_T when noise_scale=1)\n",
        "\n",
        "    Practical tips:\n",
        "      - good_refine: set reburn_frac_hit ~ 0.4-0.6, reburn_frac_miss ~ 0.9 (fallback almost random)\n",
        "      - bad_warm:    set reburn_frac_miss ~ 0.5-0.7, reburn_frac_hit ~ 0.9 (fallback almost random)\n",
        "    \"\"\"\n",
        "    import os\n",
        "    torch.manual_seed(seed); np.random.seed(seed)\n",
        "    if save_dir is not None:\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    scheduler = DDIMScheduler()\n",
        "    scheduler.set_timesteps(num_inference_steps=n_step)\n",
        "    step_size = 1000 // n_step\n",
        "    dtype = torch.float32\n",
        "\n",
        "    timesteps = list(map(int, scheduler.timesteps))           # length = n_step, descending\n",
        "    n_steps_sched = len(timesteps)                             # == n_step\n",
        "\n",
        "    def _start_idx_from_frac(frac: float) -> int:\n",
        "        # frac in [0,1]; 1.0 -> index 0 (most steps), 0.0 -> index n_step-1 (fewest steps)\n",
        "        frac = max(0.0, min(1.0, float(frac)))\n",
        "        # convert to index (round toward giving *more* steps when ambiguous)\n",
        "        # e.g., frac=0.5 with n_step=20 -> idx=10 (do ~half the schedule)\n",
        "        idx = int(round((1.0 - frac) * (n_steps_sched - 1)))\n",
        "        return max(0, min(n_steps_sched - 1, idx))\n",
        "\n",
        "    def _q_xt_given_x0(x0, t_idx, noise_scale=1.0):\n",
        "        \"\"\"Sample q(x_t|x0) at scheduler index t_idx using alphas_cumprod[t] and isotropic noise.\"\"\"\n",
        "        t_val = timesteps[t_idx]\n",
        "        alpha_bar = scheduler.alphas_cumprod[t_val].item()\n",
        "        sqrt_a = alpha_bar**0.5\n",
        "        sqrt_1ma = (1.0 - alpha_bar)**0.5\n",
        "        return sqrt_a * x0 + sqrt_1ma * torch.randn_like(x0) * noise_scale\n",
        "\n",
        "    def _random_xT_like(shape, device, dtype):\n",
        "        # If you want pure x_T (max noise), just draw a fresh x0 and reburn at idx=0 with noise=1\n",
        "        x0_init = torch.randn(shape, device=device, dtype=dtype)\n",
        "        return _q_xt_given_x0(x0_init, t_idx=0, noise_scale=1.0), 0  # start_idx=0\n",
        "\n",
        "    results_table = []\n",
        "\n",
        "    for j in image_indices:\n",
        "        filename = f\"{j:05d}.png\"\n",
        "        filepath = os.path.join(\n",
        "            \"/egr/research-slim/liangs16/Measurment_Consistent_Diffusion_Trajectory/data/demo_remain/\",\n",
        "            filename\n",
        "        )\n",
        "        gt_img = Image.open(filepath).convert(\"RGB\")\n",
        "        ref_numpy = np.array(gt_img).astype(np.float32) / 255.0\n",
        "        x = (ref_numpy * 2 - 1).transpose(2, 0, 1)\n",
        "        ref_img = torch.tensor(x, dtype=dtype, device=device).unsqueeze(0)\n",
        "        gt = (ref_img/2+0.5)\n",
        "\n",
        "        # forward measurement (no GT leakage)\n",
        "        if measure_config['operator']['name'] == 'inpainting':\n",
        "            y = operator.forward(ref_img, mask=mask)\n",
        "        else:\n",
        "            y = operator.forward(ref_img)\n",
        "        y_n = noiser(y)\n",
        "\n",
        "        print(f\"\\n[REBURN:{policy}] Image {filename}\")\n",
        "        for run_iter in range(num_runs):\n",
        "            print(f\"  Run {run_iter+1}/{num_runs}\")\n",
        "\n",
        "            # initialize: random at the *beginning* of schedule\n",
        "            x_T, start_idx = _random_xT_like((1,3,256,256), device, dtype)\n",
        "\n",
        "            best_mce_overall = float('inf')\n",
        "            best_psnr_overall = -float('inf')\n",
        "            best_final_image = None\n",
        "            best_image_path = \"\"\n",
        "\n",
        "            passes_used = 0\n",
        "\n",
        "            for pass_idx in range(total_passes):\n",
        "                passes_used += 1\n",
        "                measurement_errors = []\n",
        "                input_t = x_T.clone()\n",
        "\n",
        "                # run from start_idx to the end of schedule\n",
        "                for si in range(start_idx, n_steps_sched):\n",
        "                    t = timesteps[si]\n",
        "                    prev_timestep = t - step_size\n",
        "                    alpha_t = scheduler.alphas_cumprod[t]\n",
        "                    alpha_prev = scheduler.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else scheduler.alphas_cumprod[0]\n",
        "                    sqrt_one_minus = (1 - alpha_t)**0.5\n",
        "                    sqrt_alpha = alpha_t**0.5\n",
        "                    sqrt_alpha_prev = alpha_prev**0.5\n",
        "\n",
        "                    input_t, pred_x0, _ = optimize_input(\n",
        "                        input_t, sqrt_one_minus, sqrt_alpha, t, y_n,\n",
        "                        num_steps=inner_opt_steps, learning_rate=inner_lr\n",
        "                    )\n",
        "\n",
        "                    phase_image = (pred_x0/2+0.5).clamp(0,1)\n",
        "                    mce = compute_mce(phase_image, y_n.abs(), target_shape=y_n.shape)\n",
        "                    measurement_errors.append(mce)\n",
        "\n",
        "                    # ancestral update (unless at the very last step)\n",
        "                    if si < n_steps_sched - 1:\n",
        "                        eps = torch.randn_like(input_t)\n",
        "                        input_t = sqrt_alpha_prev * pred_x0 + (1 - alpha_prev)**0.5 * eps\n",
        "\n",
        "                # end-of-pass stats from this start_idx\n",
        "                final_x0 = pred_x0.detach()\n",
        "                final_img = (final_x0/2+0.5).clamp(0,1).squeeze(0).permute(1,2,0).cpu().numpy()\n",
        "                gt_img_np = gt[0].permute(1,2,0).detach().cpu().numpy()\n",
        "                final_psnr = compute_psnr(final_img, gt_img_np)\n",
        "                min_mce_pass = min(measurement_errors) if measurement_errors else float('inf')\n",
        "\n",
        "                print(f\"    Pass {pass_idx+1}/{total_passes} (start_idx={start_idx:02d}/{n_steps_sched-1}): \"\n",
        "                      f\"min-pass MCE={min_mce_pass:.6f}  PSNR={final_psnr:.3f} dB\")\n",
        "\n",
        "                # track best across passes\n",
        "                if min_mce_pass < best_mce_overall - 1e-12:\n",
        "                    best_mce_overall = min_mce_pass\n",
        "                    best_psnr_overall = final_psnr\n",
        "                    best_final_image = final_img\n",
        "\n",
        "                # choose next start and latent (always do next unless last pass)\n",
        "                if pass_idx < total_passes - 1:\n",
        "                    if policy == \"baseline_random\":\n",
        "                        # Always random, and start at beginning (index 0)\n",
        "                        x_T, start_idx = _random_xT_like((1,3,256,256), device, dtype)\n",
        "\n",
        "                    elif policy == \"good_refine\":\n",
        "                        if min_mce_pass <= mce_threshold:\n",
        "                            # HIT → reburn warm-start around current x0 at mid-ish steps\n",
        "                            if reburn:\n",
        "                                idx = _start_idx_from_frac(reburn_frac_hit)\n",
        "                                x_T = _q_xt_given_x0(final_x0, idx, noise_scale=restart_noise_scale)\n",
        "                                start_idx = idx\n",
        "                                print(f\"      -> HIT thr → REBURN warm-start at idx={idx} (frac≈{reburn_frac_hit:.2f})\")\n",
        "                            else:\n",
        "                                x_T, start_idx = _random_xT_like((1,3,256,256), device, dtype)\n",
        "                        else:\n",
        "                            # NOT hit → random\n",
        "                            x_T, start_idx = _random_xT_like((1,3,256,256), device, dtype)\n",
        "                            print(\"      -> NOT hit thr → random next pass\")\n",
        "\n",
        "                    elif policy == \"bad_warm\":\n",
        "                        if min_mce_pass > mce_threshold:\n",
        "                            # NOT hit → reburn warm-start\n",
        "                            if reburn:\n",
        "                                idx = _start_idx_from_frac(reburn_frac_miss)\n",
        "                                x_T = _q_xt_given_x0(final_x0, idx, noise_scale=restart_noise_scale)\n",
        "                                start_idx = idx\n",
        "                                print(f\"      -> NOT hit thr → REBURN warm-start at idx={idx} (frac≈{reburn_frac_miss:.2f})\")\n",
        "                            else:\n",
        "                                x_T, start_idx = _random_xT_like((1,3,256,256), device, dtype)\n",
        "                        else:\n",
        "                            # HIT → random\n",
        "                            x_T, start_idx = _random_xT_like((1,3,256,256), device, dtype)\n",
        "                            print(\"      -> HIT thr → random next pass\")\n",
        "\n",
        "                    else:\n",
        "                        raise ValueError(f\"Unknown policy: {policy}\")\n",
        "\n",
        "            # (optional) save best image\n",
        "            if save_dir is not None and best_final_image is not None:\n",
        "                out_path = os.path.join(save_dir, f\"reburn_{policy}_{filename}_run{run_iter}_best.png\")\n",
        "                Image.fromarray((np.clip(best_final_image,0,1)*255).astype(np.uint8)).save(out_path)\n",
        "                best_image_path = out_path\n",
        "            else:\n",
        "                best_image_path = \"\"\n",
        "\n",
        "            results_table.append({\n",
        "                \"image\": filename,\n",
        "                \"run\": run_iter,\n",
        "                \"best_mce_overall\": float(best_mce_overall),\n",
        "                \"best_psnr_overall\": float(best_psnr_overall),\n",
        "                \"policy\": policy,\n",
        "                \"threshold\": float(mce_threshold),\n",
        "                \"n_steps\": int(n_step),\n",
        "                \"passes_used\": int(passes_used),\n",
        "                \"total_passes\": int(total_passes),\n",
        "                \"restart_noise_scale\": float(restart_noise_scale),\n",
        "                \"reburn\": bool(reburn),\n",
        "                \"reburn_frac_hit\": float(reburn_frac_hit),\n",
        "                \"reburn_frac_miss\": float(reburn_frac_miss),\n",
        "                \"best_image_path\": best_image_path,\n",
        "            })\n",
        "            print(f\"  ==> Best-overall: MCE={best_mce_overall:.6f}, PSNR={best_psnr_overall:.3f} dB \"\n",
        "                  f\"(passes={passes_used})\")\n",
        "\n",
        "    # correlation across all rows\n",
        "    mces  = np.array([r[\"best_mce_overall\"]  for r in results_table], dtype=float)\n",
        "    psnrs = np.array([r[\"best_psnr_overall\"] for r in results_table], dtype=float)\n",
        "    corr = float('nan') if len(mces)<2 or np.std(mces)==0 or np.std(psnrs)==0 else float(np.corrcoef(mces, psnrs)[0,1])\n",
        "\n",
        "    print(\"\\n=== Reburn Summary ===\")\n",
        "    print(f\"Rows (image×run): {len(results_table)}\")\n",
        "    print(f\"Pearson corr(best_MCE, best_PSNR): {corr:.4f}\")\n",
        "    return results_table, corr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f20c158",
      "metadata": {
        "id": "4f20c158"
      },
      "outputs": [],
      "source": [
        "# Baseline (unchanged, always random starts)\n",
        "'''base_res, _ = run_fixed_pass_experiment_reburn(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20, total_passes=10,\n",
        "    policy=\"baseline_random\",\n",
        "    mce_threshold=0.0014,      # unused logically for baseline\n",
        "    reburn=False,              # ensure it's pure baseline\n",
        "    restart_noise_scale=0.0,\n",
        ")'''\n",
        "\n",
        "# good_refine with reburn from mid schedule when threshold is HIT\n",
        "gr_res, _ = run_fixed_pass_experiment_reburn(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20, total_passes=10,\n",
        "    policy=\"good_refine\",\n",
        "    mce_threshold=0.0016,      # looser\n",
        "    reburn=True,\n",
        "    reburn_frac_hit=0.5,       # start around the middle\n",
        "    reburn_frac_miss=0.9,      # if ever used for miss, nearly random\n",
        "    restart_noise_scale=0.5,\n",
        ")\n",
        "\n",
        "# bad_warm with reburn when threshold is NOT HIT\n",
        "bw_res, _ = run_fixed_pass_experiment_reburn(\n",
        "    image_indices=range(11,14),\n",
        "    n_step=20, total_passes=10,\n",
        "    policy=\"bad_warm\",\n",
        "    mce_threshold=0.00147,      # tighter\n",
        "    reburn=True,\n",
        "    reburn_frac_hit=0.9,       # if hit → random-like (we won't warm when hit)\n",
        "    reburn_frac_miss=0.8,      # when miss → mid/high noise to escape\n",
        "    restart_noise_scale=0.5,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6d630ef",
      "metadata": {
        "id": "d6d630ef"
      },
      "source": [
        "\n",
        "# Loop over images and show them step by step\n",
        "for i, img_tensor in enumerate(out_visual):\n",
        "    image_np = clear_color(img_tensor)\n",
        "    \n",
        "    # Display the image\n",
        "    plt.imshow(image_np)\n",
        "    plt.axis('off')  # Hide axis for better display\n",
        "    plt.title(f\"Image {i}\")  # Add title with image number\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd7b7986-e6c4-4b7d-b092-a8ffaed62c82",
      "metadata": {
        "id": "fd7b7986-e6c4-4b7d-b092-a8ffaed62c82"
      },
      "outputs": [],
      "source": [
        "plt.imshow(run_results[1])\n",
        "# plt.axis('off')\n",
        "#plt.savefig(\"ffhq0000_db2.png\", dpi=300,bbox_inches='tight', pad_inches=0)\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52715f0e-9c0c-41e0-8db0-c54191f72d5d",
      "metadata": {
        "id": "52715f0e-9c0c-41e0-8db0-c54191f72d5d"
      },
      "outputs": [],
      "source": [
        "gt = (ref_img/2+0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87251191-1fee-4758-8646-346861de9bef",
      "metadata": {
        "id": "87251191-1fee-4758-8646-346861de9bef"
      },
      "outputs": [],
      "source": [
        "plt.imshow(np.array(gt.cpu().detach().numpy()[0].transpose(1,2,0)))\n",
        "plt.axis('off')\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52286916-16e1-44cd-9db5-25f9fd80d4ec",
      "metadata": {
        "id": "52286916-16e1-44cd-9db5-25f9fd80d4ec"
      },
      "outputs": [],
      "source": [
        "def compute_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1.0  # Assuming the image is normalized to [0, 1]\n",
        "    psnr = 20 * np.log10(max_pixel / (mse**0.5))\n",
        "    return psnr.item()\n",
        "psnr_value = compute_psnr(np.array(phase_image), np.array(gt.cpu().detach().numpy()[0].transpose(1,2,0)))\n",
        "print(f\"After diffusion PSNR: {psnr_value} dB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42ded3e3-b2b0-4382-83a5-5d5551d521d5",
      "metadata": {
        "id": "42ded3e3-b2b0-4382-83a5-5d5551d521d5"
      },
      "outputs": [],
      "source": [
        "print(input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4f7ac17-c3d6-4703-988d-93d473152c43",
      "metadata": {
        "id": "c4f7ac17-c3d6-4703-988d-93d473152c43"
      },
      "outputs": [],
      "source": [
        "from piq import psnr, ssim, LPIPS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3166e37c-69c3-46dd-802b-e931adbb2dd2",
      "metadata": {
        "id": "3166e37c-69c3-46dd-802b-e931adbb2dd2"
      },
      "outputs": [],
      "source": [
        "def norm( x):\n",
        "    return (x * 0.5 + 0.5).clip(0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a16aa9-2164-4cfa-8ab0-33ca8df63ea2",
      "metadata": {
        "id": "a9a16aa9-2164-4cfa-8ab0-33ca8df63ea2"
      },
      "outputs": [],
      "source": [
        "print(psnr(norm(ref_img), norm(input), 1.0, reduction='mean'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67509136",
      "metadata": {
        "id": "67509136"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03fdfe46",
      "metadata": {
        "id": "03fdfe46"
      },
      "outputs": [],
      "source": [
        "fname = str(i).zfill(5) + 'test'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "711fc709",
      "metadata": {
        "id": "711fc709"
      },
      "source": [
        "# New: Save image to explicit folder: SITCOMOUT at Cheng_Hans\n",
        "\n",
        "# Method 1: Use PIL\n",
        "# !!NotWorking!!\n",
        "def save_image(image, folder_path, filename=\"output.png\"):\n",
        "    # Ensure the folder exists\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    # Define the full file path\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    # Save the image\n",
        "    image.save(file_path)\n",
        "    print(f\"Image saved at: {file_path}\")\n",
        "\n",
        "# Usage\n",
        "save_image(phase_image, \"/egr/research-slim/liangs16/Cheng_Hans/SITCOMOUTPUT\", \"demo_remain_00024_1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be077284",
      "metadata": {
        "id": "be077284"
      },
      "outputs": [],
      "source": [
        "#Method 2: numpy\n",
        "\n",
        "def save_image(image_array, folder_path, filename=\"output.png\"):\n",
        "    # Ensure the folder exists\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "    # Define the full file path\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "    # Save the image\n",
        "    # plt.imsave(file_path, image_array, cmap = \"gray\")  # Use `gray` for grayscale images\n",
        "    plt.imsave(file_path, image_array)\n",
        "    print(f\"Image saved at: {file_path}\")\n",
        "\n",
        "# Example Usage (creating a dummy NumPy array)\n",
        "save_image(phase_image, \"/egr/research-slim/liangs16/Cheng_Hans/SITCOMOUTPUT\", \"demo_remain_00026_1.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "680e7467",
      "metadata": {
        "id": "680e7467"
      },
      "source": [
        "gt_img = Image.open('/egr/research-slim/liangs16/Cheng_Hans/SITCOMOUTPUT/demo_remain_00024_1.png').convert(\"RGB\")\n",
        "plt.imshow(gt_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a328e996",
      "metadata": {
        "id": "a328e996"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}